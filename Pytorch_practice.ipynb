{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscalar = torch.tensor(7)\n",
    "tscalar = tf.Variable(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb40281",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvector = torch.tensor((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b8645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[2, 3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1, 2], [3, 0]])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[[[1, 2, 3]]]]).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4cc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7355ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random_normal((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55301e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand([1, 1, 3, 4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190009b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(224, 224, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(size=(3, 4), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(size=(3, 4), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.matmul(torch.zeros(size=(3, 4), dtype=torch.int32), torch.ones(size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_float32 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f918701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([[0.11111, 0.222222, 0.3333333]], dtype=torch.float64, device=torch.device('cpu:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28001dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_float32 * tensor_float32.type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand([3, 4], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08212a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor  = torch.tensor([1., 2., 3.], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d628e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(torch.matmul(tensor, tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d506773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in tensor:\n",
    "    value += i*i\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfa03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(tensor @ tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(1, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0966d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.rand(3, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2598bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[0].shape, tensor[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(tensor[0], tensor[0].T).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748db520",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([x, x, x, x, x], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88327a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_x = x.reshape(1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze(reshape_x) #removing all single dimensions from target tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.permute(2, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da210f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "array, tensor.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(5)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add772ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.rand(3, 2)\n",
    "print(x)\n",
    "torch.manual_seed(42)\n",
    "y = torch.rand(3, 2)\n",
    "print(y)\n",
    "print(x==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be44760",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.to('device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3910589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59448402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = X*weight+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "\n",
    "X = torch.arange(start, end, step=0.02).unsqueeze(dim=1)\n",
    "\n",
    "y = X * weight + bias\n",
    "\n",
    "print(X[:10], \"\\n\\n\", y[:10])\n",
    "print(\"\\n\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d35c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = int(0.8 * len(y))\n",
    "X_train, y_train = X[:sample], y[:sample]\n",
    "X_test, y_test = X[sample:], y[sample:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27205a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(traindata=X_train, trainlabel=y_train, testdata=X_test, testlabel=y_test, prediction=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(traindata, trainlabel, s=5, c='darkgreen', label = 'TrainingData')\n",
    "    plt.scatter(testdata, testlabel, s=5, c='yellow', label = 'TestData')\n",
    "    if prediction is not None:\n",
    "        plt.scatter(X_test, prediction, s=5, c='y', label='Prediction')\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d247e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ec3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Parameter(torch.randn(BS, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88df49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Parameter(torch.randn(1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31caa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):   #this contains all the bulding block for the neural network\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * X + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearregressiosmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights *  X  + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7dcced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, required_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, required_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * X + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.weights = nn.Parameter(torch.randn(1, required_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requred_grad=True, dtype=torch.float))\n",
    "    \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * X + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae38c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tarfile\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(\"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\", '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28693280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c745834",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\dines\\OneDrive\\Documents\\code-datasets\\cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b26ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFolder(path + '\\\\' + 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ae5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(path + '\\\\' + 'train', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[0][0].permute(2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[150][0].permute(2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760582c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a919b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb88d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataloader, DataLoader\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader(train_size, batch_size, shuffle=True, num_workers=4, pin_memory=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137252ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3])\n",
    "torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50105c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c078012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearRegression(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super.__init__()\n",
    "#         self.weights = nn.Parameter(torch.rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(1, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e79fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearRegression(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super.__init__()\n",
    "#         self.weights = nn.Parameter(torch.randn(1, require_grad=True, dtype=torch.float32))\n",
    "#         self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        \n",
    "#     def Forword(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         return x*self.weights+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c54a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaac56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearRegression(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "#         self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "#     def forwarded(self, X: torch.Tensor) -> torch.Tensor:\n",
    "#         return X * self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decc467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        \n",
    "    def forwaeded(self, X: torch.Tensor)-> torch.Tensor:\n",
    "        X * self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78484b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "print(list(LinearRegression().parameters()))\n",
    "LinearRegression().state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b430063e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbac944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class newclass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ab54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(newclass().parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6538e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\[[A-Za-z\\s]+\\]\\s\\([A-Za-z\\s\\|]+\\)\\s[A-Za-z\\s]+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde3c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10395ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "#         super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5471985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95c870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    def __init__(self):\n",
    "        self.weights = \"HI\"\n",
    "        print(self.weights)\n",
    "    def module(self):\n",
    "        return \"ntg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A.module()\n",
    "class B(self, a):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bias = \"Hello\"\n",
    "#         print(self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2471bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0314bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        \n",
    "        def forward(self, X:torch.tensor) -> torch.tensor:\n",
    "            X*self.weights+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "LinearRegression().parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        return F.relu(self.conv2(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model().parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "# embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "\n",
    "# lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "# hello_embed = embeds(lookup_tensor)\n",
    "# print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cce368",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Embedding(len(word_to_ix), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = nn.Parameter(torch.randn(1, requires_grad=False, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed09518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce0b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ed4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If requires_grad is set to false, you are freezing the part of the model as no changes happen to its parameters. In the example below, all layers have the parameters modified during training as requires_grad is set to true.\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad =False\n",
    "\n",
    "model.fc = nn.Sequential (OrderedDict ([('fc1', nn.Linear (512, 256)),\n",
    "('relu1', nn.ReLU ()),\n",
    "('dropout1', nn.Dropout (p = 0.5)),\n",
    "('fc2', nn.Linear (256, 128)),\n",
    "('relu2', nn.ReLU ()),\n",
    "('dropout2', nn.Dropout (p = 0.5)),\n",
    "('fc3', nn.Linear (128, 10)),\n",
    "('output', nn.LogSoftmax (dim =1))\n",
    "]))\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print('Name: ', name, ' Requires_Grad: ', param.requires_grad)\n",
    "\n",
    "# Try changing the highlighted bold text in above code to False and you will see the model is frozen except for the last ‘fc’ layer, which you have modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7fd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c139c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "fromtorch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76679ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Variables; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(torch.randn(64, 1000).type(torch.float32), requires_grad=False)\n",
    "y = Variable(torch.randn(64, 10).type(torch.float32), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621829be",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Variable(torch.randn(1000,100).type(torch.float32), requires_grad=True)\n",
    "w2 = Variable(torch.randn(100,10).type(torch.float32), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c453b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(500):\n",
    "    X.mm(w1).clamp(0).mm(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\my_submission.csv\")\n",
    "train = pd.read_csv(r\"C:/Users/dines/OneDrive/Documents/torch-nlp/train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train['text']\n",
    "df_test = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43590e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "punctuations = string.punctuation\n",
    "nlp = spacy.load('en')\n",
    "stop_words = STOP_WORDS\n",
    "parser = English()\n",
    "\n",
    "def spacy_preprocessor(sentence):\n",
    "    \"\"\"Tokenize, Lemmatize, Remove Stopwords\"\"\"\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    result = ' '.join(mytokens)\n",
    "    return result\n",
    "\n",
    "df_train = df_train.apply(lambda x: spacy_preprocessor(x))\n",
    "df_test = df_test.apply(lambda x: spacy_preprocessor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10237fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n",
    "type(parser(df_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a769cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n",
    "for i in df_train:\n",
    "    for j in parser(i):\n",
    "        if j.lemma_ == \"PRON\":\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "# sentence = \"The striped bats are hanging on their feet for best\"\n",
    "# doc = nlp(df_train[0])\n",
    "\n",
    "# for token in doc:\n",
    "#     print(token.text, \" -- \", token.pos_, \" -- \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3664019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean(data):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba9023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaning():\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "        self.stwords = list(set(spacy.lang.en.stop_words.STOP_WORDS))\n",
    "        self.punc = string.punctuation\n",
    "    def clean(self,data):\n",
    "        tokens = self.nlp(data)\n",
    "        tokens = [word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in tokens]\n",
    "        tokens = [word for word in tokens if word not in self.stwords and word not in self.punc]\n",
    "        res = ' '.join(tokens)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Cleaning()\n",
    "df_train = df_train.apply(lambda x: c.clean(x))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.apply(lambda x: c.clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['text']\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d438a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_length = 17\n",
    "text = data.Field(tokenize=\"spacy\",\n",
    "                  pad_first=True)\n",
    "\n",
    "# define train, validation and test sets\n",
    "train_data = data.TabularDataset(path=\"preprocessed_data/train.csv\",\n",
    "                                 format=\"csv\",\n",
    "                                 fields=[\n",
    "                                         ('id', data.Field()),\n",
    "                                         ('keyword', text),\n",
    "                                         ('location', data.Field()),\n",
    "                                         ('text', text),\n",
    "                                         ('target', data.Field())],\n",
    "                                 skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9172d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be441f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ecce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f06083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='dataset/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90177cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='datset/', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02780d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c96166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=input_size, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2264da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterian = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888370a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676736c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d03ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e337fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463135a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size=64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d83df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe82380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, targets) in enumerate(tqdm(d)):\n",
    "#     print(batch_idx, data.reshape(d.shape[0],-1), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de3105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee723522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch.optim as optim\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a658a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48855383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        \"\"\"\n",
    "        Here we define the layers of the network. We create two fully connected layers\n",
    "        Parameters:\n",
    "            input_size: the size of the input, in this case 784 (28x28)\n",
    "            num_classes: the number of classes we want to predict, in this case 10 (0-9)\n",
    "        \"\"\"\n",
    "        super(NN, self).__init__()\n",
    "        # Our first linear layer take input_size, in this case 784 nodes to 50\n",
    "        # and our second linear layer takes 50 to the num_classes we have, in\n",
    "        # this case 10.\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53197603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        \"\"\"\n",
    "        x here is the mnist images and we run it through fc1, fc2 that we created above.\n",
    "        we also add a ReLU activation function in between and for that (since it has no parameters)\n",
    "        I recommend using nn.functional (F)\n",
    "        Parameters:\n",
    "            x: mnist images\n",
    "        Returns:\n",
    "            out: the output of the network\n",
    "        \"\"\"\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8519cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader(train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab296e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4597d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "batch_size=64\n",
    "learning_rate=0.001\n",
    "num_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57564f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18513a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e112949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1497e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7156df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a922e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        traget = target.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def Forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "batch_size=64\n",
    "learning_rate=0.001\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74534c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "#         # Get data to cuda if possible\n",
    "#         data = data.to(device=device)\n",
    "#         targets = targets.to(device=device)\n",
    "\n",
    "#         # Get to correct shape\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "#         # Forward\n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores, targets)\n",
    "\n",
    "#         # Backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Gradient descent or adam step\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89682eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c45a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d1c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09417c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "epochs=1\n",
    "batch_size=64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f9b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27121ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, shuffle=True, batch_size=batch_size)\n",
    "test_load = DataLoader(test, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88542aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= NN(input_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f55198",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data, target) in enumerate(tqdm(train_load)):\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = torch.randn(64, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a40eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reshape(d.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.randn(1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reshape(d.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reshape(d.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7323121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16506907",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(64, 1, 28,28).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d70fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data, target) in enumerate(tqdm(train_load)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f98c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "s= model(data.reshape(data.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion(model(data.reshape(data.shape[0],-1)), torch.randn([64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b168df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6026201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(dataset=train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(dataset=test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43990622",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc425710",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model(data)\n",
    "# criterion(scores, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "batch_size=64\n",
    "epochs=3\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698617b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc05e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3da8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf91aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee558db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79eff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfea8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de724f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "#         # Get data to cuda if possible\n",
    "#         data = data.to(device=device)\n",
    "#         targets = targets.to(device=device)\n",
    "#         # Get to correct shape\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "#         # Forward\n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores, targets)\n",
    "#         # Backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         # Gradient descent or adam step\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0242fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     for idx, (data, target) in enumerate(tqdm(train_load)):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores, target)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "num_classes = 10\n",
    "learning_rate = 3e-4 # karpathy's constant\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_set = datasets.CIFAR10(\n",
    "    root=\"dataset/\", transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(loader):\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_sqrd_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean**2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "mean, std = get_mean_std(train_loader)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81870d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.CIFAR10(\n",
    "    root=\"dataset/\", transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2599d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.CIFAR10(\n",
    "    root=\"dataset/\", transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = datasets.CIFAR10(root='datasets/', transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader(dataset=train_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transfroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f61752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.fc1(F.relu(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53028027",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50621b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36072123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', transform=transforms.ToTensor(), train=True, download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efa6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        score = model(data)\n",
    "        loss = criterion(score, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Check accuracy of our trained model given a loader and a model\n",
    "    Parameters:\n",
    "        loader: torch.utils.data.DataLoader\n",
    "            A loader for the dataset you want to check accuracy on\n",
    "        model: nn.Module\n",
    "            The model you want to check accuracy on\n",
    "    Returns:\n",
    "        acc: float\n",
    "            The accuracy of the model on the dataset given by the loader\n",
    "    \"\"\"\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n",
    "\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")\n",
    "Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54757db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(3, requires_grad=False, dtype=torch.float32)\n",
    "b = torch.tensor(2, requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8873e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "  y = x * 2\n",
    "y.requires_grad\n",
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f513a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad(True):\n",
    "#     y = x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d34b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForTokenClassification, AdamW, get_linear_schedule_with_warmup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\dines\\OneDrive\\Documents\\NER\\ner_datasetreference.csv\", encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(df['Word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f91917",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = list(set(df['Tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea252032",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx  = {t:i for t, i in enumerate(tag_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ace53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_dec(object):\n",
    "    def  __init__(self, func):\n",
    "        self.func = func\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = self.func(*args, **kwargs)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ea3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_dec(func):\n",
    "    def inner(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return res\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@My_dec\n",
    "def processing(df):\n",
    "    agg_func = lambda x: [(w, p, t) for w, p, t in zip(x['Word'].values.tolist(), x['POS'].values.tolist(), x['Tag'].values.tolist())]\n",
    "    grouped = df.groupby('Sentence #').apply(agg_func)\n",
    "    sentence = [s for s in grouped]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6667c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "  y = x * 2\n",
    "y.requires_grad\n",
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f92b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad\n",
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doubler(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec75ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, X):\n",
    "        X = self.fc1(F.relu(X))\n",
    "        return self.fc2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterition = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299520e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cec10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f353b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa62412",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        traget = data.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        score = model(data)\n",
    "        loss = criterition(score, target)\n",
    "        print(loss)\n",
    "        break\n",
    "    break\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Check accuracy of our trained model given a loader and a model\n",
    "    Parameters:\n",
    "        loader: torch.utils.data.DataLoader\n",
    "            A loader for the dataset you want to check accuracy on\n",
    "        model: nn.Module\n",
    "            The model you want to check accuracy on\n",
    "    Returns:\n",
    "        acc: float\n",
    "            The accuracy of the model on the dataset given by the loader\n",
    "    \"\"\"\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n",
    "\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")\n",
    "# Footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class ProcessingTime(object):\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        res = self.func(*args, **kwargs)\n",
    "        print(\"Processed Time is {}\".format(time.time() - start_time))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a45bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c963099",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff73f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "@ProcessingTime\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "            score = model(data)\n",
    "            _, prediction = score.max(1)\n",
    "            num_correct += (prediction == y).sum()\n",
    "            num_samples += prediction.shape[0]\n",
    "        model.train()\n",
    "        return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')\n",
    "\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa87a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.convert_to_tensor(inputs)\n",
    "targets = tf.convert_to_tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.random.normal(shape=(2, 3))\n",
    "b = tf.random.normal(shape=(2, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape, w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor(3, requires_grad=True, dtype=torch.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2214f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b928b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x = torch.Tensor([[0.1, 0.2, 0.3], [0.4, 0.6, 0.8]])\n",
    "y_true = torch.Tensor([[0, 1]])\n",
    "\n",
    "W = Variable(torch.randn(1, 3), requires_grad=True)\n",
    "b = Variable(torch.randn(1, 2), requires_grad=True)\n",
    "\n",
    "y_pred = torch.nn.Sigmoid()(torch.mm(W, torch.transpose(x, 0, 1))+b)\n",
    "losses = (y_true - y_pred)**2\n",
    "avg_loss = losses.sum()/2\n",
    "avg_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "x = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.6, 0.8]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778614a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.Tensor([[0,  1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5.], requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    y = (x*3)\n",
    "    y.backward(torch.tensor([1, 1, 1, 1, 1]))\n",
    "    print(x.grad)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.], requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x**2\n",
    "print(y)\n",
    "\n",
    "x.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadaa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f511f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "batch_size = 64\n",
    "learning_rate=0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    def forward(self, X)-> torch.Tensor:\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= datasets.MNIST(root='datasets/', transform=transforms.ToTensor(), train=True, download=True)\n",
    "test = datasets.MNIST(root='datasets/', transform=transforms.ToTensor(), train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80106f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (data, target) in enumerate(tqdm(train_load)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        #Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        #Forward\n",
    "        score = model(data)\n",
    "        loss = criterion(score, target)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward\n",
    "        \n",
    "        #Gradient Decent or Adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad438b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e52a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(28*28)\n",
    "num_classes=10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    \n",
    "    def forward(self, X) -> torch.Tensor:\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603230dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a28360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = datasets.MNIST(root='datasets/', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ad638",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriation = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (data, target) in enumerate(train_load):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        score = model(data)\n",
    "        loss = criteriation(score, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac5105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb748bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "learning_rate=0.001\n",
    "batch_size=64\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b22232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, X) ->torch.Tensor:\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add056df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2afd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriation = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1156fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (data, target) in enumerate(tqdm(train_load)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        score = model(data)\n",
    "        loss = criteriation(score, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830811bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuray(loader, model):\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            score = model(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "    model.train()\n",
    "    print((num_correct/num_samples)*100.2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuray(train_load, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b12b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as FF\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d21c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b406045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4840ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root = 'datasets/', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = datasets.MNIST(root = 'datasets/', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94060745",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteration = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e583866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data, target in tqdm(train_load):\n",
    "        #get data to cuda if possisble\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        #get data into correct shaape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        #forward\n",
    "        score = model(data)\n",
    "        loss = criteration(score,target)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #gradient descent or adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            score = model(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "    model.train()\n",
    "    num_correct/num_samples\n",
    "check_accuracy(train_load, model)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d5af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60/64*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e713d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024545da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3597bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels,\n",
    "                 out_channels=8,\n",
    "                 kernel_size=3,\n",
    "                 stride=1\n",
    "                 padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8,\n",
    "                 out_channels=16,\n",
    "                 kernel_size=3\n",
    "                 stride=1,\n",
    "                 padding=1)\n",
    "        self.ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e9489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
    "                       out_channels=8,\n",
    "                         kernel_size=3,\n",
    "                         stride=1,\n",
    "                         padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = self.pool(X)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = self.pool(X)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        X = self.fc1(X)\n",
    "        return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e68272",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=1\n",
    "num_classes=10\n",
    "batch_size=64\n",
    "learning_rate=0.003\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels,num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf00bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriation = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data, target in tqdm(train_load):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        score = model(data)\n",
    "        loss = criteriation(score, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651af944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model,loader):\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            score = model(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "    model.train()\n",
    "    return num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e556704",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(model, train_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "c = nn.Conv2d(2,3, stride = 1, kernel_size=(4,5))\n",
    "print(c.weight.shape)\n",
    "print(c.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e146c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=1,\n",
    "                       out_channels=1,\n",
    "                         kernel_size=(1, 1),\n",
    "                         stride=1,\n",
    "                         padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dfae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8607651",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (28*28)\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d47257",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriation = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5823001",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_load = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data, target in tqdm(train_load):\n",
    "        #Get data into cuda if possible\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        #Get data into correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "        #forward\n",
    "        score = model(data)\n",
    "        loss = criteriation(score, target)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #gradient desent or Adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(load, model):\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in (load):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            score = model(x)\n",
    "            _, predictions = score.max(1)\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        model.train()\n",
    "    return num_correct/num_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06150341",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(train_load, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(test_load,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = nn.Conv2d(18,35, 5, stride=2)\n",
    "n2 = nn.Conv2d(35, 6, 5, stride=2)\n",
    "tinput = torch.randn(22, 18, 52, 182)\n",
    "output = n2(n1(tinput))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c73734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742abf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = nn.Conv2d(in_channels=1,out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "n2 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "tinput = torch.randn(64, 784)\n",
    "output = n1(tinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in train_load:\n",
    "    print(data.reshape(data.shape[0], -1).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ef981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fefafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, in_channels=1, num_classes=10):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(\n",
    "#             in_channels=in_channels,\n",
    "#             out_channels=8,\n",
    "#             kernel_size=3,\n",
    "#             stride=1,\n",
    "#             padding=1,\n",
    "#         )\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(\n",
    "#             in_channels=8,\n",
    "#             out_channels=16,\n",
    "#             kernel_size=3,\n",
    "#             stride=1,\n",
    "#             padding=1,\n",
    "#         )\n",
    "#         self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)\n",
    "# #         x = x.reshape(x.shape[0], -1)\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# # Set device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Hyperparameters\n",
    "# in_channels = 1\n",
    "# num_classes = 10\n",
    "# learning_rate = 3e-4 # karpathy's constant\n",
    "# batch_size = 64\n",
    "# num_epochs = 3\n",
    "\n",
    "# # Load Data\n",
    "# train_dataset = datasets.MNIST(\n",
    "#     root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    "# )\n",
    "# test_dataset = datasets.MNIST(\n",
    "#     root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    "# )\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Initialize network\n",
    "# model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Train Network\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "#         # Get data to cuda if possible\n",
    "#         data = data.to(device=device)\n",
    "#         targets = targets.to(device=device)\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "#         # forward\n",
    "#         scores = model(data)\n",
    "#         loss = criterion(scores, targets)\n",
    "\n",
    "#         # backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "\n",
    "#         # gradient descent or adam step\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8943ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=8, kernel_size=3, stride=1,padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1,padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = self.pool(X)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = self.pool(X)\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        X = self.fc1(X)\n",
    "        print(X.shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\dines\\OneDrive\\Pictures\\Screenshots\\Screenshot (61).png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = DataLoader(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(img)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb57d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1657942",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(256, 3, 150, 150)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e54496",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "bn1 = nn.BatchNorm2d(num_features=12)\n",
    "reu1 = nn.ReLU()\n",
    "pool = nn.MaxPool2d(kernel_size=2)\n",
    "conv2 = nn.Conv2d(in_channels=12, out_channels=20,  kernel_size=3, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(256, 3, 150, 150)\n",
    "img = reu1(bn1(conv1(img)))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(kernel_size=2, stride=3)\n",
    "pool(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2112a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a852dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensor\n",
    "    transforms.Normalize([0.5,0.5, 0.5], # 0-1 to [-1, 1], formula (x-mean)/std\n",
    "                        [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_train\"\n",
    "test_path = r\"C:/Users/dines/OneDrive/Documents/torch-nlp/intel_image_class/seg_test\"\n",
    "\n",
    "train_load = DataLoader(datasets.ImageFolder(train_path, transform=transforms), batch_size=64, shuffle=True)\n",
    "test_load = DataLoader(datasets.ImageFolder(test_path, transform=transforms), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        #Output_size after convalutional filter\n",
    "        #((w+2p-f)/s)+1\n",
    "        #input_shape=(256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        #((150+2(1)-3)/1)+1 = 256, 12, 150, 150\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        #shape=(256, 12, 150, 150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #shape=(256,12, 150, 150)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #If stride is not given, default value will be kernel_size.\n",
    "        #((150-2)/2)+1 = 256, 12, 75, 75\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        #((75+2(1)-3)/1)+1 = 256, 20, 75, 75\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        #((75+2(1)-3)/1)+1 = 256, 32, 75, 75\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=32*75*75, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.pool1(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.relu2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.bn3(y)\n",
    "        y = self.relu3(y)\n",
    "        y = y.reshape(y.shape[0], -1)\n",
    "        #y = y.view(-1, 32*75*75)\n",
    "        y = self.fc(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f27489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603903de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77db892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286cfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Initilise the values to monitor training accuracy and loss\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_load:\n",
    "        \n",
    "        #Check cuda is not available\n",
    "        if not torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "        #clear the gradient of all optimized variables for each batch\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass: compute predicted output by passing inputs to model\n",
    "        output = model(images)\n",
    "        #Caluclate the batch loss\n",
    "        loss = loss_function(output, labels)\n",
    "        #backward pass: compute gradient of loss with resepective of model parameters\n",
    "        loss.backward()\n",
    "        #perform a single optimization step (parameters update)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(train_loss)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d519121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in tqdm(enumerate(train_load)):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        \n",
    "#         train_loss+= loss.cpu().data*images.size(0)\n",
    "#         _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "#         train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "#     train_accuracy=train_accuracy/train_count\n",
    "#     train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "#     # Evaluation on testing dataset\n",
    "#     model.eval()\n",
    "    \n",
    "#     test_accuracy=0.0\n",
    "#     for i, (images,labels) in enumerate(test_loader):\n",
    "#         if torch.cuda.is_available():\n",
    "#             images=Variable(images.cuda())\n",
    "#             labels=Variable(labels.cuda())\n",
    "            \n",
    "#         outputs=model(images)\n",
    "#         _,prediction=torch.max(outputs.data,1)\n",
    "#         test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "#     test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "#     print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "#     #Save the best model\n",
    "#     if test_accuracy>best_accuracy:\n",
    "#         torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "#         best_accuracy=test_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e80496",
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44c3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = next(iter(train_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac81b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86127620",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "net = torch.nn.Linear(2, 1)\n",
    "print(list(net.parameters()))\n",
    "net(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9406082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(d, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7104721",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(net.parameters())[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.row_stack((np.array(list(net.parameters())[0].data), np.array(list(net.parameters())[1].data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(shape=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399df30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(net.parameters())[0].data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb19ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46680670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms = transforms.Compose([\n",
    "#     transforms.Resize((150, 150)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),  #0-255 to 0-1, numpy to tensor\n",
    "#     transforms.Normalize([0.5,0.5, 0.5], # 0-1 to [-1, 1], formula (x-mean)/std\n",
    "#                         [0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], #0-1 to [-1, 1], formula (x-mean)/std\n",
    "                        [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9959d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_train\"\n",
    "test_path = r\"C:/Users/dines/OneDrive/Documents/torch-nlp/intel_image_class/seg_test\"\n",
    "\n",
    "train_load = DataLoader(datasets.ImageFolder(train_path, transform=transforms), batch_size=64, shuffle=True)\n",
    "test_load = DataLoader(datasets.ImageFolder(test_path, transform=transforms), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9950a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, lab in train_load:\n",
    "    print(img,lab)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1472a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870df049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1282d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # 0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], # 0-1 to [-1, 1], formula is (x-mean)/std\n",
    "                        [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccfb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_train\"\n",
    "test_path = r\"C:/Users/dines/OneDrive/Documents/torch-nlp/intel_image_class/seg_test\"\n",
    "\n",
    "train_load = DataLoader(dataset=datasets.ImageFolder(root=train_path, transform=transforms), batch_size=64, shuffle=True)\n",
    "test_load = DataLoader(dataset=datasets.ImageFolder(root=test_path, transform=transforms), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e14411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20,kernel_size=3, stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=20)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc = nn.Linear(75*75*32, num_classes)\n",
    "     \n",
    "    def forward(self, input):\n",
    "        output = self.pool1(self.relu1(self.bn1(self.conv1(input))))\n",
    "        output = self.bn2(self.conv2(output))\n",
    "        output = self.relu3(self.bn3(self.conv3(output)))\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb709f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #Image shape (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        # ((150-3+2(1))/1)+1 = (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        #(256, 12, 150, 150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #(256, 12, 150, 150)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        #((150-2)/2)+1 = (256, 12, 75, 75)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        #shape=(256, 20, 75, 75)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=20)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.pool(self.relu1(self.bn1(self.conv1(input))))\n",
    "#         output = self.pool(output)\n",
    "        output = self.bn2(self.conv2(output))\n",
    "        output = self.relu3(self.bn3(self.conv3(output)))\n",
    "        output = output.reshape(output.shape[0], -1) #output.view(-1, 75*75*32)\n",
    "        output =  self.fc(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84833331",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len, test_len = len(glob(train_path+'/**/*.jpg')), len(glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #Initilize variable to monitor accuracy and loss\n",
    "    train_accuracy = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_load):\n",
    "        #Check cuda not available\n",
    "        if not torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "        ## record the average training loss, using something like\n",
    "        ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        #Clear the gradient of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass, Compute predicted output by passing input to the model\n",
    "        output = model(images)\n",
    "        loss = loss_function(output, labels)\n",
    "        #backward pass, compute gradient of loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        #performe a single optimization step\n",
    "        optimizer.step()\n",
    "        train_loss += loss*images.shape[0]\n",
    "        _, prediction = torch.max(output.data, 1)\n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    train_accuracy = train_accuracy/train_len\n",
    "    train_loss = train_loss/train_len\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in tqdm(test_load):\n",
    "        if not torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        #clear the gradient of alloptimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #Forword pass, computed predicted output by passing input to model\n",
    "        output = model(images)\n",
    "        #caluclate batch loss\n",
    "        loss = loss_function(images,labels)\n",
    "        #Backward pass, compute gradient loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import (DataLoader)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070106d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Set device\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Hyperparameters\n",
    "# input_size = 28\n",
    "# hidden_size = 256\n",
    "# num_layers = 2\n",
    "# num_classes = 10\n",
    "# sequence_length = 28\n",
    "# learning_rate = 0.005\n",
    "# batch_size = 64\n",
    "# num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet1_1\n",
    "import torch.functional as F\n",
    "from io import open\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load(r'C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\best_checkpoint.model',map_location=device)\n",
    "model = ConvNet(num_classes=6)\n",
    "model.load_state_dict(checkpoints)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d58cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=torch.load(r'C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\best_checkpoint.model',map_location=torch.device('cpu'))\n",
    "# model = torch.load('model.pth', map_location=torch.device('cpu'))\n",
    "model=ConvNet(num_classes=6)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img_path,transformer):\n",
    "    image = Image.open(img_path)\n",
    "    print(image,image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfff925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7735c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def prediction(img_path,transformer):\n",
    "    image=Image.open(img_path)\n",
    "    \n",
    "    image_tensor=transformer(image).float()\n",
    "    \n",
    "    \n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "        \n",
    "    input=Variable(image_tensor)\n",
    "    \n",
    "    \n",
    "    output=model(input)\n",
    "    \n",
    "    index=output.data.numpy().argmax()\n",
    "    \n",
    "    pred=classes[index]\n",
    "    \n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path=glob.glob(r'C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_pred'+'\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict={}\n",
    "\n",
    "for i in images_path:\n",
    "    pred_dict[i[i.rfind('/')+1:]]=prediction(i, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81feda79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define a loss tensor and a batch of 10 samples\n",
    "loss = torch.tensor([2.0])\n",
    "images = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "# Compute the total loss using loss.item()\n",
    "total_loss_1 = 0.0\n",
    "for i in range(10):\n",
    "    total_loss_1 += loss.item()\n",
    "\n",
    "# Compute the total loss using loss * images.shape[0]\n",
    "total_loss_2 = 0.0\n",
    "for i in range(10):\n",
    "    total_loss_2 += loss * images.shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Total loss using loss.item():\", total_loss_1)  # Should be 20.0\n",
    "print(\"Total loss using loss * images.shape[0]:\", total_loss_2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.tensor([2.0])\n",
    "images = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "print(type(loss.item()), type(loss), images.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d63866",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss1 = 0.0\n",
    "for i in range(10):\n",
    "    total_loss1 += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define a loss tensor and a batch of 10 samples\n",
    "loss = torch.tensor([2.0])\n",
    "images = torch.randn(10, 3, 32, 32)\n",
    "\n",
    "# Compute the total loss using loss.item()\n",
    "total_loss_1 = 0.0\n",
    "for i in range(10):\n",
    "    total_loss_1 += loss.item()\n",
    "\n",
    "# Compute the total loss using loss * images.numel()\n",
    "total_loss_2 = 0.0\n",
    "for i in range(10):\n",
    "    total_loss_2 += loss * images.numel()\n",
    "\n",
    "# Print the results\n",
    "print(\"Total loss using loss.item():\", total_loss_1)  # Should be 20.0\n",
    "print(\"Total loss using loss * images.numel():\", total_loss_2.item())  # Should also be 20.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac86acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in {\"/content/gdrive/MyDrive/seg_test.zip\": \"/content/seg_test\", \"/content/gdrive/MyDrive/seg_train.zip\": \"/content/seg_train\", \"/content/gdrive/MyDrive/seg_pred.zip\": \"/content/seg_pred\"}.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8810c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1701624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c84ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #Image shape (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        #((150-3+2(1))/1)+1 = (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        #((150-2)/2)+1 defualt value of stride is kernel_size, shape=(256, 12, 75, 75)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        #((150-3+2(1))/1)+1 = shape is (256, 20, 75, 75)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=20)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(32*75*75, num_classes)\n",
    "    def forward(self, input):\n",
    "        output = self.pool1(self.relu1(self.bn1(self.conv1(input))))\n",
    "        output = self.relu2(self.bn2(self.conv2(output)))\n",
    "        output = self.relu3(self.bn3(self.conv3(output)))\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eef5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],#0-1 to [-1 to 1], formula is (x-mean)/std\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_pred\"\n",
    "pred_imgs = glob(pred_path+'\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_points = torch.load(r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\best_checkpoint.model\", map_location=device)\n",
    "model = ConvNet(num_classes=6)\n",
    "model.load_state_dict(check_points)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001eda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(r\"C:\\Users\\dines\\OneDrive\\Documents\\torch-nlp\\intel_image_class\\seg_train\")\n",
    "import random\n",
    "classes =random.sample(classes, len(classes))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2b3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4556f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def prediction(img_path,transformer):\n",
    "    image=Image.open(img_path)\n",
    "    image_tensor=transformer(image).float()\n",
    "    image_tensor=image_tensor.unsqueeze_(0)\n",
    "    if torch.cuda.is_available():\n",
    "        image_tensor.cuda()\n",
    "    input=Variable(image_tensor)\n",
    "    output=model(input)\n",
    "    index=output.data.numpy().argmax()\n",
    "    pred=classes[index]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = pred_imgs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4575cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],#0-1 to [-1 to 1], formula is (x-mean)/std\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])\n",
    "image = cv2.imread(test_image, cv2.IMREAD_COLOR)\n",
    "image_tensor = transforms(image).float()\n",
    "image_tensor = image_tensor.unsqueeze_(0)\n",
    "if not torch.cuda.is_available():\n",
    "    image_tensor.to(device)\n",
    "input = Variable(image_tensor)\n",
    "output = model(input)\n",
    "index = output.data.numpy().argmax()\n",
    "classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transforms = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(), #0-255 to 0-1, numpy to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],#0-1 to [-1 to 1], formula is (x-mean)/std\n",
    "                         [0.5, 0.5, 0.5])\n",
    "])\n",
    "image = Image.open(test_image)\n",
    "image_tensor = transforms(image).float()\n",
    "image_tensor = image_tensor.unsqueeze_(0)\n",
    "if not torch.cuda.is_available():\n",
    "    image_tensor.to(device)\n",
    "input = Variable(image_tensor)\n",
    "output = model(input)\n",
    "index = output.data.numpy().argmax()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1df92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def xavier_init(tensor):\n",
    "    init.xavier_uniform_(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0117a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = MyNet()\n",
    "\n",
    "with torch.no_grad():\n",
    "    xavier_init(net.fc1.weight)\n",
    "    xavier_init(net.fc2.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4af403",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sequence = \"the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Convert the text sequence to a list of words\n",
    "words = text_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e53a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "print(f\"a:{a:3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43578e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = f(x)\n",
    "z = y + 3\n",
    "\n",
    "# Backpropagation\n",
    "z.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(x.grad) # Output: tensor([4.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142629d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = f(x)\n",
    "z = y+3\n",
    "#backprogration\n",
    "z.backward()\n",
    "\n",
    "#print gradients\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b596087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.3 (20230416.2022)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"109pt\" height=\"271pt\"\n",
       " viewBox=\"0.00 0.00 109.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-267 105,-267 105,4 -4,4\"/>\n",
       "<!-- 2388666049616 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2388666049616</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2388673928208 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2388673928208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-86 6,-86 6,-67 95,-67 95,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 2388673928208&#45;&gt;2388666049616 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2388673928208&#45;&gt;2388666049616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.54C50.5,-59.99 50.5,-50.77 50.5,-42.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-42.06 50.5,-32.06 47,-42.06 54,-42.06\"/>\n",
       "</g>\n",
       "<!-- 2388673928544 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2388673928544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-141 6,-141 6,-122 95,-122 95,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 2388673928544&#45;&gt;2388673928208 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2388673928544&#45;&gt;2388673928208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-121.75C50.5,-115.11 50.5,-105.73 50.5,-97.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-97.44 50.5,-87.44 47,-97.44 54,-97.44\"/>\n",
       "</g>\n",
       "<!-- 2388673928592 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2388673928592</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 2388673928592&#45;&gt;2388673928544 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2388673928592&#45;&gt;2388673928544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.75C50.5,-170.11 50.5,-160.73 50.5,-152.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-152.44 50.5,-142.44 47,-152.44 54,-152.44\"/>\n",
       "</g>\n",
       "<!-- 2388666470544 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2388666470544</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 2388666470544&#45;&gt;2388673928592 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2388666470544&#45;&gt;2388673928592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.61C50.5,-224.18 50.5,-215.08 50.5,-207.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-207.16 50.5,-197.16 47,-207.16 54,-207.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22c1f86b730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "make_dot(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1) -> AccumulateGrad -> PowBackward0 -> AddBackward0 -> (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the sample image\n",
    "image = cv2.imread('sample_image.jpg')\n",
    "\n",
    "# Define a set of image augmentations to apply\n",
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=256, height=256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2)\n",
    "])\n",
    "\n",
    "# Apply the augmentations to the image\n",
    "augmented_image = transform(image=image)['image']\n",
    "\n",
    "# Visualize the original and augmented images side by side\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title('Augmented Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\dines\\Music\\Work\\pytorch_practice\\captcha_images_v2\\2b827.png\")\n",
    "transform = A.transposeform([\n",
    "    A.Normalize(always_apply=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee460083",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = r\"C:\\Users\\dines\\Music\\Work\\pytorch_practice\\captcha_images_v2\\226md.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a101970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'226md'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(img).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "718b2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_DIR = r\"C:\\Users\\dines\\Music\\Work\\pytorch_practice\\captcha_images_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c1a7775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yyn57'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r\"\\\\|\\.\", glob(Data_DIR+\"\\*.png\")[-1])[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80c36f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\dines\\\\Music\\\\Work\\\\pytorch_practice\\\\captcha_images_v2\\\\226md.png']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\"\\\\|.\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81cffb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_DIR = 'C:\\\\Users\\\\dines\\\\Music\\\\Work\\\\pytorch_practice\\\\captcha_images_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "674c67de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2', '2', '6', 'm', 'd'], ['2', '2', 'd', '5', 'n'], ['2', '3', '5', '6', 'g'], ['2', '3', 'm', 'd', 'g'], ['2', '3', 'n', '8', '8'], ['2', '4', '3', 'm', 'm'], ['2', '4', '4', 'e', '2'], ['2', '4', '5', 'y', '5'], ['2', '4', 'f', '6', 'w'], ['2', '4', 'p', 'e', 'w'], ['2', '5', '2', '5', '7'], ['2', '5', '3', 'd', 'c'], ['2', '5', 'e', 'g', 'p'], ['2', '5', 'm', '6', 'p'], ['2', '5', 'p', '2', 'm'], ['2', '5', 'w', '5', '3'], ['2', '6', '4', 'm', '5'], ['2', '6', '8', 'g', '2'], ['2', '8', '3', '4', '8'], ['2', '8', 'x', '4', '7'], ['2', 'b', '8', '2', '7'], ['2', 'b', 'g', '4', '8'], ['2', 'c', 'e', 'g', 'f'], ['2', 'c', 'g', '5', '8'], ['2', 'c', 'g', 'y', 'x'], ['2', 'e', 'n', '7', 'g'], ['2', 'e', 'n', 'f', '4'], ['2', 'f', 'x', 'g', 'd'], ['2', 'g', '7', '8', '3'], ['2', 'g', '7', 'n', 'm'], ['2', 'g', 'y', 'b', '6'], ['2', 'm', 'g', '8', '7'], ['2', 'm', 'p', 'n', 'n'], ['2', 'n', '7', '3', 'f'], ['2', 'n', 'b', 'c', 'x'], ['2', 'n', 'f', '2', '6'], ['2', 'n', 'p', 'g', '6'], ['2', 'n', 'x', '3', '8'], ['2', 'p', '2', 'y', '8'], ['2', 'p', 'f', 'p', 'n'], ['2', 'w', '4', 'y', '7'], ['2', 'w', 'c', '3', '8'], ['2', 'w', 'x', '7', '3'], ['2', 'x', '7', 'b', 'm'], ['2', 'x', 'c', '2', 'n'], ['2', 'y', 'c', 'n', '8'], ['2', 'y', 'g', 'g', 'g'], ['3', '2', '5', 'f', 'b'], ['3', '2', 'c', 'n', 'n'], ['3', '2', 'd', 'n', 'n'], ['3', '3', 'b', '2', '2'], ['3', '3', 'f', '7', 'm'], ['3', '3', 'n', '7', '3'], ['3', '3', 'n', 'g', '4'], ['3', '3', 'p', '4', 'e'], ['3', '4', 'b', '8', '4'], ['3', '4', 'f', 'x', 'm'], ['3', '4', 'p', 'c', 'n'], ['3', '6', '8', 'y', '5'], ['3', '6', 'b', 'c', '2'], ['3', '6', 'n', 'x', '4'], ['3', '6', 'w', '2', '5'], ['3', '7', '3', 'g', 'b'], ['3', '7', '7', 'x', 'x'], ['3', '7', '8', 'e', '5'], ['3', '7', 'd', '5', '2'], ['3', '7', 'e', 'p', '6'], ['3', '8', '7', 'g', '2'], ['3', '8', 'n', '5', '7'], ['3', 'b', '4', 'w', 'e'], ['3', 'b', 'd', '8', 'f'], ['3', 'b', 'f', 'n', 'd'], ['3', 'b', 'n', 'y', 'f'], ['3', 'b', 'x', '8', '6'], ['3', 'c', 'p', 'w', 'b'], ['3', 'd', '7', 'b', 'd'], ['3', 'd', 'e', 'n', '6'], ['3', 'd', 'g', 'm', 'f'], ['3', 'e', 'b', 'n', 'n'], ['3', 'e', 'b', 'p', 'w'], ['3', 'e', 'n', 'y', '7'], ['3', 'f', 'b', 'x', 'd'], ['3', 'g', '2', 'w', '6'], ['3', 'm', 'x', 'd', 'n'], ['3', 'n', '2', 'b', '4'], ['3', 'n', '3', 'c', 'f'], ['3', 'n', '7', 'm', 'x'], ['3', 'n', 'd', 'x', 'd'], ['3', 'n', 'f', 'd', 'n'], ['3', 'n', 'n', 'p', 'w'], ['3', 'n', 'w', '7', 'w'], ['3', 'n', 'y', '4', '5'], ['3', 'p', '4', 'n', 'n'], ['3', 'p', '6', '7', 'n'], ['3', 'p', 'e', '4', 'g'], ['3', 'w', '2', 'b', 'w'], ['3', 'w', 'n', 'd', '3'], ['3', 'x', '3', '2', '5'], ['3', 'x', '5', 'f', 'm'], ['3', 'x', 'c', 'g', 'g'], ['3', 'x', 'n', 'g', '6'], ['3', 'y', 'e', '2', 'e'], ['3', 'y', 'g', 'd', 'e'], ['3', 'y', 'm', '7', 'f'], ['4', '2', '8', 'b', '6'], ['4', '2', 'd', 'w', '4'], ['4', '2', 'n', 'x', 'y'], ['4', '2', 'x', 'p', 'y'], ['4', '3', 'g', 'e', 'y'], ['4', '3', 'm', 'n', '5'], ['4', '3', 'p', '5', 'd'], ['4', '3', 'x', 'f', 'e'], ['4', '4', '3', '3', 'm'], ['4', '4', '5', 'c', 'c'], ['4', '4', 'c', '2', '2'], ['4', '4', 'f', 'y', 'b'], ['4', '4', 'x', 'e', '8'], ['4', '4', 'y', 'p', 'e'], ['4', '6', '7', 'd', '5'], ['4', '6', 'm', 'b', 'm'], ['4', '7', '4', '3', 'p'], ['4', '7', '4', 'f', 'f'], ['4', '7', '8', 'n', 'x'], ['4', '7', 'e', '4', 'p'], ['4', '7', 'm', '2', 'b'], ['4', '8', '8', 'd', 'e'], ['4', 'b', '2', 'p', 'w'], ['4', 'c', '8', 'n', '8'], ['4', 'c', 'f', 'w', '8'], ['4', 'c', 'n', '7', 'b'], ['4', 'd', '2', '2', 'm'], ['4', 'd', 'g', 'f', '7'], ['4', 'd', 'w', '3', 'w'], ['4', 'e', 'g', 'e', 'm'], ['4', 'e', 'x', 'n', 'n'], ['4', 'f', '8', 'y', 'p'], ['4', 'f', 'c', '3', '6'], ['4', 'f', 'p', '5', 'g'], ['4', 'g', 'b', '3', 'f'], ['4', 'g', 'y', 'c', 'b'], ['4', 'm', '2', 'w', '5'], ['4', 'n', '2', 'y', 'g'], ['4', 'n', '3', 'm', 'n'], ['4', 'n', 'c', '3', '7'], ['4', 'n', 'n', 'f', '3'], ['4', 'w', '6', 'm', 'w'], ['4', 'w', '7', '6', 'g'], ['4', 'y', 'c', '8', '5'], ['4', 'y', 'c', 'e', 'x'], ['4', 'y', 'n', 'f', '3'], ['5', '2', '4', '4', '7'], ['5', '3', '2', '5', 'm'], ['5', '3', '7', 'n', 'f'], ['5', '3', 'm', 'n', '8'], ['5', '3', 'w', 'b', '8'], ['5', '3', 'w', 'p', '3'], ['5', '5', '6', 'w', 'd'], ['5', '5', 'w', '5', 'c'], ['5', '5', 'y', '2', 'm'], ['5', '6', 'c', '3', '4'], ['5', '6', 'm', '6', 'y'], ['5', '6', 'n', 'c', 'x'], ['5', '7', '3', 'b', 'n'], ['5', '7', '3', 'd', '8'], ['5', '7', '4', 'd', '7'], ['5', '7', 'b', '2', '7'], ['5', '7', 'g', 'n', 'x'], ['5', '7', 'w', 'd', 'p'], ['5', '8', 'b', '5', 'm'], ['5', '8', 'p', 'n', 'p'], ['5', 'b', 'b', '6', '6'], ['5', 'b', 'g', '8', 'f'], ['5', 'b', 'g', 'p', '2'], ['5', 'b', 'n', 'd', '7'], ['5', 'd', 'x', 'n', 'm'], ['5', 'e', 'p', '3', 'n'], ['5', 'e', 'x', 'p', 'p'], ['5', 'f', '3', 'g', 'f'], ['5', 'f', 'y', 'e', 'm'], ['5', 'g', '5', 'e', '5'], ['5', 'g', 'c', 'd', '3'], ['5', 'm', 'c', 'y', '7'], ['5', 'm', 'f', '7', 'c'], ['5', 'm', 'f', 'f', 'f'], ['5', 'm', 'g', 'n', '4'], ['5', 'm', 'n', 'p', 'd'], ['5', 'n', '2', '4', '5'], ['5', 'n', '3', 'w', '4'], ['5', 'n', '7', '2', '8'], ['5', 'n', '7', '3', '2'], ['5', 'n', 'g', '6', 'e'], ['5', 'n', 'g', 'g', 'g'], ['5', 'n', 'm', '6', 'd'], ['5', 'n', 'n', 'f', 'f'], ['5', 'n', 'p', '4', 'm'], ['5', 'n', 'p', 'd', 'n'], ['5', 'n', 'x', 'n', 'n'], ['5', 'p', '3', 'm', 'm'], ['5', 'p', '8', 'f', 'm'], ['5', 'p', 'm', '6', 'b'], ['5', 'w', 'd', 'd', 'w'], ['5', 'x', '5', 'n', 'x'], ['5', 'x', '7', 'x', '5'], ['5', 'x', 'd', '2', 'e'], ['5', 'x', 'w', 'c', 'g'], ['5', 'y', 'w', 'w', 'f'], ['5', 'y', 'x', 'g', 'p'], ['6', '2', 'n', 'b', '3'], ['6', '3', '8', '2', '4'], ['6', '3', 'p', 'x', 'e'], ['6', '4', '6', 'x', '8'], ['6', '4', 'b', '3', 'p'], ['6', '4', 'm', '8', '2'], ['6', '5', '8', 'x', 'e'], ['6', '5', 'e', 'b', 'm'], ['6', '5', 'm', '8', '5'], ['6', '6', '2', 'b', 'w'], ['6', '6', '4', 'd', 'n'], ['6', '6', '4', 'n', 'f'], ['6', '6', 'w', 'p', '5'], ['6', '7', '5', 'p', '3'], ['6', '7', '7', 'g', '3'], ['6', '7', '8', 'w', '3'], ['6', '7', 'd', 'e', 'y'], ['6', '8', '2', '5', 'y'], ['6', '8', 'w', 'f', 'd'], ['6', '8', 'x', '4', '8'], ['6', 'b', '4', '6', 'g'], ['6', 'b', '4', 'w', '6'], ['6', 'b', 'd', 'n', '5'], ['6', 'b', 'n', 'n', 'm'], ['6', 'b', 'x', 'w', 'g'], ['6', 'c', '3', 'n', '6'], ['6', 'c', '3', 'p', '5'], ['6', 'c', 'm', '6', 'm'], ['6', 'c', 'w', 'x', 'e'], ['6', 'd', 'd', '2', 'y'], ['6', 'd', 'm', 'x', '7'], ['6', 'e', '2', 'd', 'g'], ['6', 'e', '5', '5', '4'], ['6', 'e', '6', 'p', 'n'], ['6', 'e', 'c', 'b', 'n'], ['6', 'e', 'n', 'd', '3'], ['6', 'f', '2', 'y', 'c'], ['6', 'f', '8', '5', '7'], ['6', 'f', 'g', '8', 'c'], ['6', 'f', 'g', 'd', 'w'], ['6', 'f', 'n', '8', '4'], ['6', 'g', '4', '5', 'w'], ['6', 'g', 'e', '3', 'p'], ['6', 'g', 'n', 'm', '3'], ['6', 'm', '5', 'e', 'g'], ['6', 'm', 'e', 'g', 'e'], ['6', 'm', 'n', '8', 'n'], ['6', 'm', 'y', 'g', 'b'], ['6', 'n', '4', '4', '3'], ['6', 'n', '5', 'f', 'd'], ['6', 'n', '6', 'g', 'g'], ['6', 'n', 'g', '6', 'n'], ['6', 'n', 'g', '6', 'w'], ['6', 'p', '2', 'g', 'e'], ['6', 'p', '7', 'g', 'x'], ['6', 'p', 'f', 'y', '4'], ['6', 'p', 'w', 'c', 'n'], ['6', 'w', 'b', '7', '6'], ['6', 'w', 'g', '4', 'n'], ['6', 'w', 'n', 'y', 'c'], ['6', 'x', 'e', 'n', '4'], ['6', 'x', 'p', 'm', 'e'], ['6', 'x', 'x', 'd', 'x'], ['6', 'y', 'd', 'y', 'p'], ['7', '2', '8', 'n', '8'], ['7', '2', 'm', '6', 'f'], ['7', '3', 'm', 'n', 'x'], ['7', '4', '8', '5', '3'], ['7', '4', 'e', 'y', 'g'], ['7', '5', 'p', 'f', 'w'], ['7', '6', '3', '4', 'y'], ['7', '6', '3', '5', '3'], ['7', '6', 'n', '7', 'p'], ['7', '6', 'n', 'x', 'n'], ['7', '6', 'y', '6', 'f'], ['7', '7', '3', '8', '7'], ['7', '7', 'n', '6', 'g'], ['7', '7', 'w', 'p', '4'], ['7', '8', '5', 'n', '4'], ['7', '8', 'e', 'e', 'c'], ['7', 'b', '4', 'b', 'm'], ['7', 'b', 'b', '7', 'b'], ['7', 'b', 'w', 'm', '2'], ['7', 'c', 'd', 'g', 'e'], ['7', 'c', 'g', 'y', 'm'], ['7', 'd', '4', '4', 'm'], ['7', 'd', 'g', 'c', '2'], ['7', 'd', 'w', 'x', '4'], ['7', 'd', 'x', 'b', 'd'], ['7', 'd', 'y', 'w', 'w'], ['7', 'e', '2', 'y', '7'], ['7', 'f', '8', 'b', '3'], ['7', 'f', 'd', 'e', '7'], ['7', 'f', 'm', 'c', 'y'], ['7', 'g', '3', 'n', 'f'], ['7', 'g', 'c', 'e', '6'], ['7', 'g', 'm', 'f', '3'], ['7', 'g', 'n', 'g', 'e'], ['7', 'g', 'p', '4', '7'], ['7', 'm', '8', 'p', 'x'], ['7', 'm', 'g', 'm', 'f'], ['7', 'n', 'n', 'n', 'x'], ['7', 'p', '8', '5', '2'], ['7', 'p', 'c', 'd', '7'], ['7', 'p', 'n', '5', 'g'], ['7', 'w', '6', '7', 'm'], ['7', 'w', 'n', '7', '4'], ['7', 'w', 'n', 'p', 'm'], ['7', 'w', 'y', 'p', '4'], ['7', 'x', 'c', 'y', 'd'], ['7', 'x', 'd', '5', 'm'], ['7', 'y', '2', 'x', '4'], ['7', 'y', 'f', '6', '2'], ['8', '2', '3', 'p', '2'], ['8', '2', 'f', 'x', '2'], ['8', '3', '2', 'f', '3'], ['8', '4', 'w', '7', 'x'], ['8', '5', '6', '2', '2'], ['8', '5', 'd', 'x', 'n'], ['8', '6', '5', 'w', 'm'], ['8', '6', '8', '4', 'm'], ['8', '7', 'd', '4', 'c'], ['8', '7', 'n', 'y', 'm'], ['8', '8', 'b', 'g', 'x'], ['8', '8', 'y', '5', '2'], ['8', 'b', '7', '3', '5'], ['8', 'b', 'b', 'm', '4'], ['8', 'b', 'b', 'w', '8'], ['8', 'c', '2', '3', 'f'], ['8', 'c', '2', 'w', 'y'], ['8', 'c', 'c', 'c', 'c'], ['8', 'c', 'm', '4', '6'], ['8', 'd', '2', 'n', 'd'], ['8', 'd', '4', 'w', 'm'], ['8', 'd', '8', 'e', 'p'], ['8', 'd', 'b', '6', '7'], ['8', 'e', '3', '2', 'm'], ['8', 'e', 'g', 'g', 'g'], ['8', 'f', 'e', 'x', 'n'], ['8', 'g', '4', 'y', 'p'], ['8', 'g', 'e', 'c', 'm'], ['8', 'g', 'f', '7', 'n'], ['8', 'g', 'm', 'c', '4'], ['8', 'g', 'm', 'n', 'x'], ['8', 'n', '2', 'p', 'g'], ['8', 'n', '3', '4', 'n'], ['8', 'n', '4', 'n', '8'], ['8', 'n', '5', '6', 'm'], ['8', 'n', '5', 'p', '3'], ['8', 'n', '5', 'p', 'n'], ['8', 'n', '6', '2', 'n'], ['8', 'n', '6', '5', 'n'], ['8', 'n', 'b', 'e', 'w'], ['8', 'n', 'e', '4', 'g'], ['8', 'n', 'n', '7', '3'], ['8', 'n', 'p', '2', '2'], ['8', 'n', 'p', 'd', '5'], ['8', 'n', 'p', 'e', '3'], ['8', 'p', 'f', 'x', 'x'], ['8', 'w', '7', '5', '4'], ['8', 'w', '8', '7', '5'], ['8', 'w', 'y', '7', 'd'], ['8', 'x', 'e', 'f', '7'], ['8', 'y', '6', '3', 'f'], ['8', 'y', '6', 'b', '3'], ['8', 'y', 'p', 'd', 'n'], ['b', '2', '6', 'n', 'd'], ['b', '2', '8', 'g', '8'], ['b', '2', 'g', '8', 'e'], ['b', '2', 'n', 'e', 'n'], ['b', '3', '5', 'f', '6'], ['b', '3', 'x', 'p', 'n'], ['b', '4', '3', 'n', 'w'], ['b', '4', 'd', '7', 'c'], ['b', '4', 'n', 'c', 'n'], ['b', '4', 'y', '5', 'x'], ['b', '5', '5', 'd', '6'], ['b', '5', 'd', 'n', '4'], ['b', '5', 'f', 'm', '7'], ['b', '5', 'n', 'm', 'm'], ['b', '5', 'p', 'n', 'n'], ['b', '6', '8', '5', 'n'], ['b', '6', 'f', '2', 'p'], ['b', '8', '4', 'x', 'c'], ['b', 'b', 'y', 'm', 'y'], ['b', 'c', '8', 'n', 'f'], ['b', 'c', 'w', 'n', 'n'], ['b', 'd', '3', 'b', '7'], ['b', 'd', 'b', 'b', '3'], ['b', 'd', 'g', '8', '4'], ['b', 'e', '3', 'b', 'p'], ['b', 'e', '6', 'n', 'p'], ['b', 'e', 'f', 'b', 'd'], ['b', 'f', '5', '2', 'c'], ['b', 'g', 'b', '4', '8'], ['b', 'g', 'd', '4', 'm'], ['b', 'g', 'e', 'm', '5'], ['b', 'm', '3', 'p', '8'], ['b', 'm', 'x', 'p', 'e'], ['b', 'n', '5', 'm', 'w'], ['b', 'n', 'c', '2', 'f'], ['b', 'n', 'c', '5', 'f'], ['b', 'n', 'y', '2', '3'], ['b', 'n', 'y', '4', 'w'], ['b', 'p', '2', 'd', '4'], ['b', 'p', '6', 'm', 'w'], ['b', 'p', 'w', 'd', '7'], ['b', 'w', '4', '4', 'w'], ['b', 'w', '5', 'n', 'f'], ['b', 'w', '5', 'y', 'm'], ['b', 'w', '6', 'n', '6'], ['b', 'w', 'm', 'e', 'e'], ['b', 'x', 'x', 'f', 'c'], ['b', 'y', '5', 'y', '3'], ['b', 'y', 'c', '8', '2'], ['b', 'y', 'f', 'g', 'n'], ['c', '2', 'f', 'b', '7'], ['c', '2', 'g', '4', 'd'], ['c', '2', 'p', 'g', '6'], ['c', '2', 'y', 'n', '8'], ['c', '3', '5', '3', 'e'], ['c', '3', '5', '7', '2'], ['c', '3', 'n', '8', 'x'], ['c', '4', '3', 'b', '4'], ['c', '4', '5', '2', '7'], ['c', '4', '8', '2', 'b'], ['c', '4', 'b', 'g', 'd'], ['c', '4', 'b', 'n', 'y'], ['c', '4', 'm', 'c', 'm'], ['c', '5', '5', 'c', '6'], ['c', '5', 'x', 'n', 'e'], ['c', '6', '7', '4', '5'], ['c', '6', 'f', '8', 'g'], ['c', '6', 'w', 'e', '6'], ['c', '7', '5', '3', 'e'], ['c', '7', 'g', 'b', '3'], ['c', '7', 'n', 'n', '8'], ['c', '8', '6', 'm', 'd'], ['c', '8', 'f', 'x', 'y'], ['c', '8', 'n', '8', 'c'], ['c', 'b', '8', 'c', 'f'], ['c', 'c', '8', '4', '5'], ['c', 'c', 'f', '2', 'w'], ['c', 'c', 'n', '2', 'x'], ['c', 'd', '4', 'e', 'g'], ['c', 'd', '6', 'p', '4'], ['c', 'd', 'c', 'b', '3'], ['c', 'd', 'f', '7', '7'], ['c', 'd', 'f', 'e', 'n'], ['c', 'd', 'm', 'n', '8'], ['c', 'e', 'n', '5', '5'], ['c', 'e', 'w', 'n', 'm'], ['c', 'f', 'c', '2', 'y'], ['c', 'f', 'c', '5', '6'], ['c', 'f', 'f', 'p', '4'], ['c', 'f', 'n', '5', '3'], ['c', 'f', 'p', '8', '6'], ['c', 'f', 'w', '6', 'e'], ['c', 'g', '5', 'd', 'd'], ['c', 'g', 'c', 'g', 'b'], ['c', 'm', '6', 'y', 'b'], ['c', 'n', 'e', 'x', '4'], ['c', 'n', 'm', 'n', 'n'], ['c', 'n', 'w', 'y', 'c'], ['c', 'p', 'c', '8', 'c'], ['c', 'p', 'e', '6', '3'], ['c', 'w', 'd', 'n', 'x'], ['c', 'w', 'g', 'y', 'x'], ['c', 'w', 'm', 'n', 'y'], ['c', 'x', '3', 'w', 'g'], ['c', 'y', '3', 'n', 'w'], ['d', '2', '2', 'b', 'd'], ['d', '2', '2', 'n', '7'], ['d', '2', '2', 'y', '5'], ['d', '2', '3', '6', 'n'], ['d', '2', 'n', 'b', 'n'], ['d', '2', 'y', 'c', 'w'], ['d', '3', '7', '8', 'n'], ['d', '3', 'c', '7', 'y'], ['d', '3', 'c', '8', 'y'], ['d', '3', 'y', 'c', 'n'], ['d', '4', 'n', '8', '2'], ['d', '4', 'p', 'p', 'y'], ['d', '6', '6', '6', 'm'], ['d', '6', '6', 'c', 'n'], ['d', '6', 'f', 'c', 'n'], ['d', '7', '5', 'b', '5'], ['d', '7', 'c', '5', 'x'], ['d', '7', 'e', 'n', '3'], ['d', '7', 'n', 'n', '3'], ['d', '8', 'd', 'c', 'e'], ['d', '8', 'x', 'c', 'n'], ['d', 'b', 'e', 'x', '3'], ['d', 'b', 'f', 'e', 'n'], ['d', 'b', 'n', 'y', '3'], ['d', 'b', 'p', 'c', 'd'], ['d', 'c', '4', '3', '6'], ['d', 'c', 'e', '8', 'y'], ['d', 'c', 'n', 'p', '8'], ['d', 'd', '5', 'w', '5'], ['d', 'd', '7', '6', '4'], ['d', 'd', 'c', 'd', 'd'], ['d', 'd', 'c', 'n', 'e'], ['d', 'd', 'm', 'y', 'g'], ['d', 'd', 'n', 'p', 'f'], ['d', 'd', 'p', 'y', 'b'], ['d', 'e', '4', '5', 'x'], ['d', 'e', '7', 'f', '8'], ['d', 'e', 'e', 'p', '5'], ['d', 'e', 'f', 'y', 'x'], ['d', 'e', 'n', 'e', 'b'], ['d', 'f', 'n', 'x', '4'], ['d', 'm', 'w', '8', 'n'], ['d', 'm', 'x', '8', 'p'], ['d', 'm', 'x', 'p', '8'], ['d', 'n', '2', '6', 'n'], ['d', 'n', '2', 'y', 'm'], ['d', 'n', '5', 'd', 'f'], ['d', 'n', 'm', 'd', '8'], ['d', 'n', 'n', 'e', '7'], ['d', 'n', 'x', 'd', 'p'], ['d', 'p', 'b', 'y', 'd'], ['d', 'w', '3', 'n', 'n'], ['d', 'w', '6', 'm', 'n'], ['d', 'w', '8', 'd', '3'], ['d', 'x', 'w', 'c', 'w'], ['d', 'y', '3', 'c', 'x'], ['d', 'y', 'p', '7', 'n'], ['d', 'y', 'x', 'n', 'c'], ['e', '2', '5', 'x', 'g'], ['e', '2', 'd', '6', '6'], ['e', '2', 'm', 'g', '2'], ['e', '3', 'n', 'd', 'n'], ['e', '4', '3', 'y', 'm'], ['e', '4', '6', 'p', 'd'], ['e', '4', '6', 'y', 'w'], ['e', '4', 'g', 'd', '7'], ['e', '5', 'n', '6', '6'], ['e', '6', '6', '7', 'x'], ['e', '6', 'b', '7', 'y'], ['e', '6', 'm', '6', 'p'], ['e', '7', '2', 'c', 'd'], ['e', '7', '6', 'n', '4'], ['e', '7', 'n', 'x', '4'], ['e', '7', 'x', '4', '5'], ['e', '8', '4', 'n', '2'], ['e', '8', 'd', 'x', 'n'], ['e', '8', 'e', '5', 'e'], ['e', 'b', 'c', 'b', 'x'], ['e', 'c', '6', 'p', 'm'], ['e', 'c', 'd', '4', 'w'], ['e', 'd', 'g', '3', 'p'], ['e', 'd', 'w', 'n', 'y'], ['e', 'e', '8', 'f', 'g'], ['e', 'e', 'n', '2', '3'], ['e', 'f', '4', 'm', 'n'], ['e', 'f', '4', 'n', 'p'], ['e', 'f', 'b', '3', 'f'], ['e', 'f', 'e', '6', '2'], ['e', 'f', 'g', '7', '2'], ['e', 'f', 'g', 'x', '5'], ['e', 'f', 'x', '3', '4'], ['e', 'g', 'x', 'm', 'p'], ['e', 'm', 'w', 'p', 'n'], ['e', 'n', '3', '2', 'e'], ['e', 'n', '4', 'n', '4'], ['e', 'n', 'g', '5', '3'], ['e', 'n', 'n', '7', 'n'], ['e', 'n', 'n', 'm', 'm'], ['e', 'n', 'p', 'w', '2'], ['e', 'p', '8', '5', 'x'], ['e', 'p', 'p', 'g', '3'], ['e', 'w', 'c', 'f', '5'], ['e', 'w', 'n', 'x', '8'], ['e', 'x', 'c', 'm', 'n'], ['e', 'x', 'y', 'c', 'n'], ['f', '2', '2', '8', 'n'], ['f', '2', '2', 'b', 'n'], ['f', '2', 'f', 'g', 'e'], ['f', '2', 'm', '8', 'n'], ['f', '3', '5', 'x', 'p'], ['f', '3', '6', '4', 'x'], ['f', '4', 'f', 'n', '2'], ['f', '4', 'w', 'f', 'n'], ['f', '5', 'c', 'm', '2'], ['f', '5', 'e', '5', 'e'], ['f', '6', 'n', 'e', '5'], ['f', '6', 'w', 'w', '8'], ['f', '7', '4', 'x', '3'], ['f', '7', '5', '3', 'f'], ['f', '7', '5', 'c', 'x'], ['f', '7', 'c', 'e', 'y'], ['f', '8', '3', 'p', 'n'], ['f', '8', '5', '8', 'x'], ['f', '8', '5', 'y', '3'], ['f', '8', 'f', '8', 'g'], ['f', 'b', 'p', '2', 'c'], ['f', 'c', '2', 'f', 'f'], ['f', 'c', '6', 'x', 'b'], ['f', 'c', 'e', 'y', '3'], ['f', 'c', 'm', 'e', 'm'], ['f', 'c', 'n', 'e', '6'], ['f', 'd', 'p', 'g', 'd'], ['f', 'e', 'y', 'c', '8'], ['f', 'f', 'd', '6', 'p'], ['f', 'f', 'n', 'x', 'n'], ['f', 'f', 'p', 'x', 'f'], ['f', 'g', '3', '8', 'b'], ['f', 'g', '7', 'm', 'g'], ['f', 'g', '8', 'n', '4'], ['f', 'n', 'b', 'f', 'w'], ['f', 'n', 'c', 'n', 'b'], ['f', 'p', '3', '8', '2'], ['f', 'p', '3', 'w', 'y'], ['f', 'p', '5', 'w', 'n'], ['f', 'p', '7', '6', '2'], ['f', 'p', 'w', '7', '6'], ['f', 'w', '3', 'b', '2'], ['f', 'w', 'x', 'd', 'p'], ['f', 'x', 'p', 'w', '3'], ['f', 'y', '2', 'n', 'd'], ['f', 'y', 'f', 'b', 'n'], ['f', 'y', 'w', 'b', '8'], ['g', '2', '4', '7', 'w'], ['g', '2', '5', '7', '7'], ['g', '2', 'f', 'n', 'w'], ['g', '3', 'd', 'y', '6'], ['g', '3', 'e', 'x', '3'], ['g', '5', '5', 'b', '4'], ['g', '6', 'n', '7', 'x'], ['g', '7', '8', 'g', 'n'], ['g', '7', 'f', 'm', 'c'], ['g', '7', 'g', 'n', 'f'], ['g', '7', 'w', 'x', 'w'], ['g', '8', '4', '2', 'c'], ['g', '8', '8', '8', 'x'], ['g', '8', 'g', 'n', 'd'], ['g', 'b', 'x', 'y', 'y'], ['g', 'c', '2', '7', '7'], ['g', 'c', '2', 'w', 'd'], ['g', 'c', '8', '3', 'b'], ['g', 'c', 'f', 'g', 'p'], ['g', 'c', 'x', '6', 'f'], ['g', 'd', '4', 'm', 'f'], ['g', 'd', '8', 'f', 'b'], ['g', 'd', 'n', 'g', '3'], ['g', 'e', 'c', 'm', 'f'], ['g', 'e', 'g', 'w', '4'], ['g', 'e', 'w', 'f', 'y'], ['g', 'f', '2', 'g', '4'], ['g', 'f', 'b', 'x', '6'], ['g', 'f', 'p', '5', '4'], ['g', 'f', 'x', 'c', 'c'], ['g', 'g', 'd', '7', 'm'], ['g', 'm', '2', 'c', '2'], ['g', 'm', '6', 'n', 'n'], ['g', 'm', '7', 'n', '8'], ['g', 'n', '2', 'd', '3'], ['g', 'n', '2', 'x', 'y'], ['g', 'n', 'b', 'd', 'e'], ['g', 'n', 'b', 'n', '4'], ['g', 'n', 'c', '3', 'n'], ['g', 'n', 'f', '8', '5'], ['g', 'n', 'g', '6', 'e'], ['g', 'n', 'y', '6', 'b'], ['g', 'p', '2', '2', 'x'], ['g', 'p', '7', 'c', '5'], ['g', 'p', 'n', 'x', 'n'], ['g', 'p', 'x', 'n', 'g'], ['g', 'w', '4', '6', '8'], ['g', 'w', '5', '3', 'm'], ['g', 'w', 'n', '5', '3'], ['g', 'w', 'n', 'm', '6'], ['g', 'x', 'x', '2', 'p'], ['g', 'x', 'x', 'p', 'f'], ['g', 'y', '4', '3', '3'], ['g', 'y', '5', 'b', 'f'], ['g', 'y', '8', 'x', 'b'], ['g', 'y', 'm', 'm', 'n'], ['m', '2', '2', 'e', '3'], ['m', '2', '3', 'b', 'p'], ['m', '2', '5', '7', '6'], ['m', '2', 'n', 'f', '4'], ['m', '3', '5', '8', '8'], ['m', '3', 'b', '5', 'p'], ['m', '3', 'w', 'f', 'w'], ['m', '4', '4', '8', 'b'], ['m', '4', '5', '7', 'd'], ['m', '4', 'f', 'd', '8'], ['m', '4', 'g', '8', 'g'], ['m', '5', 'm', 'e', 'g'], ['m', '5', 'y', 'm', '2'], ['m', '6', '7', 'b', '3'], ['m', '6', 'n', '4', 'x'], ['m', '7', '4', 'd', 'm'], ['m', '7', '5', 'b', 'f'], ['m', '8', 'g', 'm', 'x'], ['m', '8', 'm', '4', 'x'], ['m', 'b', '4', 'e', 'n'], ['m', 'b', 'f', '5', '8'], ['m', 'b', 'p', '2', 'y'], ['m', 'c', '3', '5', 'n'], ['m', 'c', '8', 'w', '2'], ['m', 'c', 'c', '2', 'x'], ['m', 'c', 'g', '4', '3'], ['m', 'c', 'y', 'f', 'x'], ['m', 'd', '3', '4', '4'], ['m', 'd', 'd', 'g', 'b'], ['m', 'd', 'x', 'p', 'n'], ['m', 'd', 'y', 'p', '7'], ['m', 'e', 'n', '4', 'f'], ['m', 'f', 'b', '3', 'x'], ['m', 'f', 'c', '3', '5'], ['m', 'g', '5', 'n', 'n'], ['m', 'g', 'd', 'w', 'b'], ['m', 'g', 'g', 'c', 'e'], ['m', 'g', 'w', '3', 'n'], ['m', 'm', '3', 'n', 'n'], ['m', 'm', 'c', '5', 'n'], ['m', 'm', 'f', 'm', '6'], ['m', 'm', 'g', '2', 'm'], ['m', 'm', 'g', '3', '8'], ['m', 'm', 'y', '5', 'n'], ['m', 'n', '5', 'c', '4'], ['m', 'n', 'e', 'f', '5'], ['m', 'p', '7', 'w', 'p'], ['m', 'p', 'm', 'y', '5'], ['m', 'p', 'x', 'f', 'b'], ['m', 'w', '5', 'p', '2'], ['m', 'w', 'd', 'f', '6'], ['m', 'w', 'x', 'w', 'p'], ['m', 'x', '8', 'b', 'b'], ['m', 'x', 'n', 'w', '4'], ['m', 'x', 'y', 'x', 'w'], ['m', 'y', '8', '4', 'e'], ['m', 'y', 'c', '3', 'c'], ['m', 'y', 'e', '6', '8'], ['m', 'y', 'f', '8', '2'], ['n', '2', '6', '5', 'y'], ['n', '2', 'b', 'y', '7'], ['n', '2', 'g', 'm', 'g'], ['n', '3', '3', '6', 'e'], ['n', '3', '7', '3', 'n'], ['n', '3', 'b', 'm', '6'], ['n', '3', 'f', 'f', 'n'], ['n', '3', 'm', '6', 'x'], ['n', '3', 'x', '4', 'c'], ['n', '4', '6', '4', 'c'], ['n', '4', 'b', '4', 'm'], ['n', '4', 'c', 'p', 'y'], ['n', '4', 'w', 'w', 'n'], ['n', '4', 'x', 'x', '5'], ['n', '5', 'c', 'm', '7'], ['n', '5', 'n', '8', 'b'], ['n', '5', 'w', '5', 'g'], ['n', '5', 'w', 'b', 'g'], ['n', '5', 'x', '2', 'n'], ['n', '6', 'f', '4', 'b'], ['n', '6', 'n', 'n', '2'], ['n', '6', 'x', 'c', '5'], ['n', '7', 'd', 'y', 'b'], ['n', '7', 'e', 'b', 'x'], ['n', '7', 'e', 'n', 'n'], ['n', '7', 'f', 'f', '2'], ['n', '7', 'g', '4', 'f'], ['n', '7', 'm', 'e', 'b'], ['n', '8', 'f', 'p', '6'], ['n', '8', 'p', 'f', 'e'], ['n', '8', 'y', 'd', 'd'], ['n', 'b', '2', '6', '7'], ['n', 'b', '4', '5', 'd'], ['n', 'b', 'c', 'g', 'b'], ['n', 'b', 'f', '8', 'm'], ['n', 'b', 'f', 'x', '5'], ['n', 'b', 'm', 'x', '7'], ['n', 'b', 'p', '3', 'e'], ['n', 'b', 'w', 'n', 'n'], ['n', 'b', 'w', 'p', 'n'], ['n', 'c', '4', 'y', 'g'], ['n', 'c', 'f', 'g', 'b'], ['n', 'c', 'w', '4', 'g'], ['n', 'c', 'w', 'w', '7'], ['n', 'c', 'y', 'x', '8'], ['n', 'd', '5', 'w', 'g'], ['n', 'd', 'e', 'c', 'c'], ['n', 'd', 'g', '2', 'b'], ['n', 'd', 'm', 'e', '7'], ['n', 'd', 'y', 'f', 'e'], ['n', 'e', '3', '2', '5'], ['n', 'e', 'e', 'c', 'd'], ['n', 'e', 'g', 'g', 'n'], ['n', 'f', '2', 'n', '8'], ['n', 'f', '7', 'b', 'n'], ['n', 'f', '8', 'b', '8'], ['n', 'f', 'b', 'g', '8'], ['n', 'f', 'c', 'b', '5'], ['n', 'f', 'c', 'w', 'y'], ['n', 'f', 'd', '8', 'g'], ['n', 'f', 'g', '2', '3'], ['n', 'f', 'n', 'd', 'w'], ['n', 'g', '2', 'g', 'w'], ['n', 'g', '4', '6', 'm'], ['n', 'g', '6', 'y', 'p'], ['n', 'g', '7', '5', '6'], ['n', 'g', 'n', '2', '6'], ['n', 'm', '2', '4', '8'], ['n', 'm', '4', '6', 'n'], ['n', 'm', 'w', '4', '6'], ['n', 'm', 'y', '2', 'x'], ['n', 'n', '4', 'w', 'x'], ['n', 'n', '6', 'm', 'g'], ['n', 'n', 'f', '8', 'b'], ['n', 'n', 'f', 'x', '3'], ['n', 'n', 'g', 'x', 'c'], ['n', 'n', 'n', '5', '7'], ['n', 'n', 'n', '5', 'p'], ['n', 'n', 'p', '4', 'e'], ['n', 'n', 'y', '5', 'e'], ['n', 'p', 'x', 'b', '7'], ['n', 'w', '5', 'b', '2'], ['n', 'w', 'f', 'd', 'e'], ['n', 'w', 'g', '2', 'm'], ['n', 'w', 'n', 'c', 'n'], ['n', 'x', 'c', '8', '3'], ['n', 'x', 'c', 'm', 'n'], ['n', 'x', 'n', '4', 'f'], ['n', 'x', 'x', '2', '5'], ['n', 'x', 'x', 'f', '8'], ['n', 'y', '3', 'd', 'w'], ['n', 'y', '3', 'n', 'n'], ['n', 'y', '5', 'd', 'p'], ['n', 'y', '8', 'n', 'p'], ['n', 'y', 'b', 'c', 'x'], ['p', '2', '4', 'g', 'n'], ['p', '2', 'd', 'w', '7'], ['p', '2', 'm', '6', 'n'], ['p', '2', 'x', '7', 'x'], ['p', '2', 'y', 'm', '2'], ['p', '4', 'n', 'm', '4'], ['p', '4', 'p', 'd', 'e'], ['p', '5', '7', 'f', 'n'], ['p', '5', 'g', '5', 'm'], ['p', '5', 'n', 'c', 'e'], ['p', '6', 'm', 'n', '8'], ['p', '7', 'f', 'y', 'p'], ['p', '8', 'c', '2', '4'], ['p', '8', 'n', 'g', 'x'], ['p', '8', 'w', 'w', 'f'], ['p', 'b', 'p', 'g', 'c'], ['p', 'c', 'e', 'd', 'e'], ['p', 'c', 'm', '7', 'f'], ['p', 'c', 'p', 'g', '6'], ['p', 'd', 'c', 'p', '4'], ['p', 'd', 'w', '3', '8'], ['p', 'd', 'y', 'c', '8'], ['p', 'e', '4', 'x', 'n'], ['p', 'f', '4', 'n', 'b'], ['p', 'f', '5', 'n', 'g'], ['p', 'g', '2', 'p', 'm'], ['p', 'g', '2', 'y', 'x'], ['p', 'g', '4', 'b', 'f'], ['p', 'g', 'g', '3', 'n'], ['p', 'g', 'm', '2', 'e'], ['p', 'g', 'm', 'n', '2'], ['p', 'g', 'w', 'n', 'p'], ['p', 'm', '3', '6', '3'], ['p', 'm', '4', '7', 'f'], ['p', 'm', 'd', '3', 'w'], ['p', 'm', 'e', '8', '6'], ['p', 'm', 'f', '5', 'w'], ['p', 'm', 'g', '5', '5'], ['p', 'n', '7', 'p', 'n'], ['p', 'n', 'm', 'x', 'f'], ['p', 'n', 'n', 'w', 'y'], ['p', 'p', '5', '4', '6'], ['p', 'p', '8', '7', 'n'], ['p', 'p', 'w', 'y', 'd'], ['p', 'p', 'x', '7', '7'], ['p', 'w', '5', 'n', 'c'], ['p', 'w', 'e', 'b', 'm'], ['p', 'w', 'm', 'b', 'n'], ['p', 'w', 'n', '5', 'e'], ['p', 'x', '2', 'x', 'p'], ['p', 'x', '8', 'n', '8'], ['p', 'x', 'd', 'w', 'p'], ['p', 'x', 'n', 'e', '8'], ['p', 'y', 'b', 'e', 'e'], ['p', 'y', 'e', 'f', 'b'], ['p', 'y', 'f', '6', '5'], ['p', 'y', 'm', '7', 'p'], ['w', '2', 'e', '8', '7'], ['w', '2', 'n', '7', 'e'], ['w', '2', 'y', 'p', '7'], ['w', '4', '6', 'e', 'p'], ['w', '4', '8', 'c', 'w'], ['w', '4', 'c', 'd', 'c'], ['w', '4', 'c', 'n', 'n'], ['w', '4', 'n', 'f', 'x'], ['w', '4', 'x', '2', 'm'], ['w', '5', '2', 'f', 'n'], ['w', '6', 'p', 'x', 'y'], ['w', '6', 'y', 'n', 'e'], ['w', '7', '5', 'w', '8'], ['w', '7', 'e', '6', 'm'], ['w', '8', 'b', 'n', 'x'], ['w', '8', 'f', '3', '6'], ['w', 'b', '3', 'e', 'd'], ['w', 'b', 'n', 'c', 'w'], ['w', 'c', '2', 'b', 'd'], ['w', 'c', 'e', '5', 'n'], ['w', 'd', '2', 'g', 'b'], ['w', 'd', 'd', 'c', 'p'], ['w', 'd', 'w', 'w', '8'], ['w', 'e', 'c', 'f', 'd'], ['w', 'f', '6', '8', '4'], ['w', 'f', 'y', '5', 'm'], ['w', 'g', '6', '2', '5'], ['w', 'g', 'n', 'w', 'p'], ['w', 'm', '4', '7', 'f'], ['w', 'm', '7', '4', '6'], ['w', 'm', 'p', 'm', 'p'], ['w', 'n', 'm', 'y', 'n'], ['w', 'n', 'p', 'e', 'c'], ['w', 'w', 'm', 'n', '6'], ['w', 'x', 'c', 'n', '8'], ['w', 'x', 'y', '4', 'n'], ['w', 'y', 'c', '2', '5'], ['w', 'y', 'e', '8', '5'], ['x', '2', '7', '7', 'e'], ['x', '2', 'c', 'n', 'n'], ['x', '3', '4', '7', 'n'], ['x', '3', '6', '2', 'g'], ['x', '3', '7', 'b', 'f'], ['x', '3', '8', 'f', 'n'], ['x', '3', 'd', 'e', 'b'], ['x', '3', 'f', 'w', 'f'], ['x', '4', '4', 'n', '4'], ['x', '4', '5', '8', 'w'], ['x', '4', 'f', '7', 'g'], ['x', '4', 'g', 'g', '5'], ['x', '4', 'p', 'n', 'p'], ['x', '5', 'f', '5', '4'], ['x', '5', 'n', 'y', 'n'], ['x', '6', 'b', '5', 'm'], ['x', '6', 'p', 'd', 'b'], ['x', '7', '4', '2', '2'], ['x', '7', '4', 'b', '2'], ['x', '7', '5', '4', '7'], ['x', '7', '6', 'm', 'n'], ['x', '7', '7', '4', '6'], ['x', '7', '7', '5', 'w'], ['x', '8', 'e', '8', 'n'], ['x', '8', 'x', 'n', 'p'], ['x', 'b', 'c', 'b', 'x'], ['x', 'b', 'e', 'm', '6'], ['x', 'c', '6', '8', 'n'], ['x', 'c', 'e', '8', 'd'], ['x', 'c', 'f', '8', '8'], ['x', 'c', 'm', 'b', 'p'], ['x', 'd', 'c', 'n', '4'], ['x', 'd', 'n', '6', '5'], ['x', 'e', '6', 'e', 'b'], ['x', 'e', '8', 'x', 'm'], ['x', 'e', 'm', 'y', 'g'], ['x', 'f', '4', 'p', '4'], ['x', 'f', '5', 'g', '7'], ['x', 'f', 'g', '6', '5'], ['x', 'f', 'g', 'x', 'b'], ['x', 'f', 'n', '6', 'n'], ['x', 'g', 'c', 'x', 'y'], ['x', 'm', 'c', 'y', 'm'], ['x', 'n', 'd', '3', 'y'], ['x', 'n', 'f', 'x', '5'], ['x', 'n', 'g', 'x', 'c'], ['x', 'n', 'n', '4', 'd'], ['x', 'n', 'n', 'c', '3'], ['x', 'p', '2', '4', 'p'], ['x', 'w', '4', '6', '5'], ['x', 'w', 'x', '7', 'd'], ['x', 'x', 'b', 'm', '5'], ['x', 'x', 'n', 'e', 'y'], ['x', 'x', 'w', '4', '4'], ['x', 'y', 'm', 'f', 'n'], ['x', 'y', 'n', 'c', 'c'], ['x', 'y', 'y', 'y', 'w'], ['y', '2', '4', '3', '6'], ['y', '2', 'x', 'g', '4'], ['y', '2', 'y', 'e', '8'], ['y', '3', '2', 'y', 'y'], ['y', '3', '3', 'n', 'm'], ['y', '3', 'c', '5', '8'], ['y', '4', '8', 'c', '3'], ['y', '4', 'e', 'c', '2'], ['y', '4', 'g', '3', 'b'], ['y', '4', 'n', '6', 'm'], ['y', '5', '3', 'c', '2'], ['y', '5', 'd', 'p', 'p'], ['y', '5', 'g', '8', '7'], ['y', '5', 'n', '6', 'd'], ['y', '5', 'w', '2', '8'], ['y', '7', 'd', '7', '5'], ['y', '7', 'm', 'n', 'm'], ['y', '7', 'x', '8', 'p'], ['y', '8', '6', '6', 'y'], ['y', 'b', 'f', 'x', '6'], ['y', 'c', 'm', 'c', 'w'], ['y', 'c', 'n', 'f', 'c'], ['y', 'd', '3', '8', 'e'], ['y', 'd', '3', 'm', '3'], ['y', 'd', '7', '5', '5'], ['y', 'd', 'd', '3', 'g'], ['y', 'd', 'g', '8', 'n'], ['y', 'e', 'm', 'y', '4'], ['y', 'e', 'w', '6', 'p'], ['y', 'e', 'y', 'n', '4'], ['y', 'f', '2', '8', 'd'], ['y', 'f', '3', '4', '7'], ['y', 'f', '4', '2', '4'], ['y', 'f', 'd', 'n', '7'], ['y', 'g', '5', 'b', 'b'], ['y', 'g', 'e', 'n', 'n'], ['y', 'g', 'f', 'w', 'e'], ['y', 'm', 'p', '7', 'g'], ['y', 'p', 'p', '8', 'f'], ['y', 'p', 'w', '3', 'd'], ['y', 'w', '6', '6', '7'], ['y', 'w', '7', 'n', 'y'], ['y', 'w', 'n', '6', 'f'], ['y', 'x', '2', 'd', '4'], ['y', 'x', 'd', '7', 'm'], ['y', 'y', '8', '2', '4'], ['y', 'y', 'g', '5', 'g'], ['y', 'y', 'n', '5', '7']]\n",
      "['2', '2', '6', 'm', 'd', '2', '2', 'd', '5', 'n', '2', '3', '5', '6', 'g', '2', '3', 'm', 'd', 'g', '2', '3', 'n', '8', '8', '2', '4', '3', 'm', 'm', '2', '4', '4', 'e', '2', '2', '4', '5', 'y', '5', '2', '4', 'f', '6', 'w', '2', '4', 'p', 'e', 'w', '2', '5', '2', '5', '7', '2', '5', '3', 'd', 'c', '2', '5', 'e', 'g', 'p', '2', '5', 'm', '6', 'p', '2', '5', 'p', '2', 'm', '2', '5', 'w', '5', '3', '2', '6', '4', 'm', '5', '2', '6', '8', 'g', '2', '2', '8', '3', '4', '8', '2', '8', 'x', '4', '7', '2', 'b', '8', '2', '7', '2', 'b', 'g', '4', '8', '2', 'c', 'e', 'g', 'f', '2', 'c', 'g', '5', '8', '2', 'c', 'g', 'y', 'x', '2', 'e', 'n', '7', 'g', '2', 'e', 'n', 'f', '4', '2', 'f', 'x', 'g', 'd', '2', 'g', '7', '8', '3', '2', 'g', '7', 'n', 'm', '2', 'g', 'y', 'b', '6', '2', 'm', 'g', '8', '7', '2', 'm', 'p', 'n', 'n', '2', 'n', '7', '3', 'f', '2', 'n', 'b', 'c', 'x', '2', 'n', 'f', '2', '6', '2', 'n', 'p', 'g', '6', '2', 'n', 'x', '3', '8', '2', 'p', '2', 'y', '8', '2', 'p', 'f', 'p', 'n', '2', 'w', '4', 'y', '7', '2', 'w', 'c', '3', '8', '2', 'w', 'x', '7', '3', '2', 'x', '7', 'b', 'm', '2', 'x', 'c', '2', 'n', '2', 'y', 'c', 'n', '8', '2', 'y', 'g', 'g', 'g', '3', '2', '5', 'f', 'b', '3', '2', 'c', 'n', 'n', '3', '2', 'd', 'n', 'n', '3', '3', 'b', '2', '2', '3', '3', 'f', '7', 'm', '3', '3', 'n', '7', '3', '3', '3', 'n', 'g', '4', '3', '3', 'p', '4', 'e', '3', '4', 'b', '8', '4', '3', '4', 'f', 'x', 'm', '3', '4', 'p', 'c', 'n', '3', '6', '8', 'y', '5', '3', '6', 'b', 'c', '2', '3', '6', 'n', 'x', '4', '3', '6', 'w', '2', '5', '3', '7', '3', 'g', 'b', '3', '7', '7', 'x', 'x', '3', '7', '8', 'e', '5', '3', '7', 'd', '5', '2', '3', '7', 'e', 'p', '6', '3', '8', '7', 'g', '2', '3', '8', 'n', '5', '7', '3', 'b', '4', 'w', 'e', '3', 'b', 'd', '8', 'f', '3', 'b', 'f', 'n', 'd', '3', 'b', 'n', 'y', 'f', '3', 'b', 'x', '8', '6', '3', 'c', 'p', 'w', 'b', '3', 'd', '7', 'b', 'd', '3', 'd', 'e', 'n', '6', '3', 'd', 'g', 'm', 'f', '3', 'e', 'b', 'n', 'n', '3', 'e', 'b', 'p', 'w', '3', 'e', 'n', 'y', '7', '3', 'f', 'b', 'x', 'd', '3', 'g', '2', 'w', '6', '3', 'm', 'x', 'd', 'n', '3', 'n', '2', 'b', '4', '3', 'n', '3', 'c', 'f', '3', 'n', '7', 'm', 'x', '3', 'n', 'd', 'x', 'd', '3', 'n', 'f', 'd', 'n', '3', 'n', 'n', 'p', 'w', '3', 'n', 'w', '7', 'w', '3', 'n', 'y', '4', '5', '3', 'p', '4', 'n', 'n', '3', 'p', '6', '7', 'n', '3', 'p', 'e', '4', 'g', '3', 'w', '2', 'b', 'w', '3', 'w', 'n', 'd', '3', '3', 'x', '3', '2', '5', '3', 'x', '5', 'f', 'm', '3', 'x', 'c', 'g', 'g', '3', 'x', 'n', 'g', '6', '3', 'y', 'e', '2', 'e', '3', 'y', 'g', 'd', 'e', '3', 'y', 'm', '7', 'f', '4', '2', '8', 'b', '6', '4', '2', 'd', 'w', '4', '4', '2', 'n', 'x', 'y', '4', '2', 'x', 'p', 'y', '4', '3', 'g', 'e', 'y', '4', '3', 'm', 'n', '5', '4', '3', 'p', '5', 'd', '4', '3', 'x', 'f', 'e', '4', '4', '3', '3', 'm', '4', '4', '5', 'c', 'c', '4', '4', 'c', '2', '2', '4', '4', 'f', 'y', 'b', '4', '4', 'x', 'e', '8', '4', '4', 'y', 'p', 'e', '4', '6', '7', 'd', '5', '4', '6', 'm', 'b', 'm', '4', '7', '4', '3', 'p', '4', '7', '4', 'f', 'f', '4', '7', '8', 'n', 'x', '4', '7', 'e', '4', 'p', '4', '7', 'm', '2', 'b', '4', '8', '8', 'd', 'e', '4', 'b', '2', 'p', 'w', '4', 'c', '8', 'n', '8', '4', 'c', 'f', 'w', '8', '4', 'c', 'n', '7', 'b', '4', 'd', '2', '2', 'm', '4', 'd', 'g', 'f', '7', '4', 'd', 'w', '3', 'w', '4', 'e', 'g', 'e', 'm', '4', 'e', 'x', 'n', 'n', '4', 'f', '8', 'y', 'p', '4', 'f', 'c', '3', '6', '4', 'f', 'p', '5', 'g', '4', 'g', 'b', '3', 'f', '4', 'g', 'y', 'c', 'b', '4', 'm', '2', 'w', '5', '4', 'n', '2', 'y', 'g', '4', 'n', '3', 'm', 'n', '4', 'n', 'c', '3', '7', '4', 'n', 'n', 'f', '3', '4', 'w', '6', 'm', 'w', '4', 'w', '7', '6', 'g', '4', 'y', 'c', '8', '5', '4', 'y', 'c', 'e', 'x', '4', 'y', 'n', 'f', '3', '5', '2', '4', '4', '7', '5', '3', '2', '5', 'm', '5', '3', '7', 'n', 'f', '5', '3', 'm', 'n', '8', '5', '3', 'w', 'b', '8', '5', '3', 'w', 'p', '3', '5', '5', '6', 'w', 'd', '5', '5', 'w', '5', 'c', '5', '5', 'y', '2', 'm', '5', '6', 'c', '3', '4', '5', '6', 'm', '6', 'y', '5', '6', 'n', 'c', 'x', '5', '7', '3', 'b', 'n', '5', '7', '3', 'd', '8', '5', '7', '4', 'd', '7', '5', '7', 'b', '2', '7', '5', '7', 'g', 'n', 'x', '5', '7', 'w', 'd', 'p', '5', '8', 'b', '5', 'm', '5', '8', 'p', 'n', 'p', '5', 'b', 'b', '6', '6', '5', 'b', 'g', '8', 'f', '5', 'b', 'g', 'p', '2', '5', 'b', 'n', 'd', '7', '5', 'd', 'x', 'n', 'm', '5', 'e', 'p', '3', 'n', '5', 'e', 'x', 'p', 'p', '5', 'f', '3', 'g', 'f', '5', 'f', 'y', 'e', 'm', '5', 'g', '5', 'e', '5', '5', 'g', 'c', 'd', '3', '5', 'm', 'c', 'y', '7', '5', 'm', 'f', '7', 'c', '5', 'm', 'f', 'f', 'f', '5', 'm', 'g', 'n', '4', '5', 'm', 'n', 'p', 'd', '5', 'n', '2', '4', '5', '5', 'n', '3', 'w', '4', '5', 'n', '7', '2', '8', '5', 'n', '7', '3', '2', '5', 'n', 'g', '6', 'e', '5', 'n', 'g', 'g', 'g', '5', 'n', 'm', '6', 'd', '5', 'n', 'n', 'f', 'f', '5', 'n', 'p', '4', 'm', '5', 'n', 'p', 'd', 'n', '5', 'n', 'x', 'n', 'n', '5', 'p', '3', 'm', 'm', '5', 'p', '8', 'f', 'm', '5', 'p', 'm', '6', 'b', '5', 'w', 'd', 'd', 'w', '5', 'x', '5', 'n', 'x', '5', 'x', '7', 'x', '5', '5', 'x', 'd', '2', 'e', '5', 'x', 'w', 'c', 'g', '5', 'y', 'w', 'w', 'f', '5', 'y', 'x', 'g', 'p', '6', '2', 'n', 'b', '3', '6', '3', '8', '2', '4', '6', '3', 'p', 'x', 'e', '6', '4', '6', 'x', '8', '6', '4', 'b', '3', 'p', '6', '4', 'm', '8', '2', '6', '5', '8', 'x', 'e', '6', '5', 'e', 'b', 'm', '6', '5', 'm', '8', '5', '6', '6', '2', 'b', 'w', '6', '6', '4', 'd', 'n', '6', '6', '4', 'n', 'f', '6', '6', 'w', 'p', '5', '6', '7', '5', 'p', '3', '6', '7', '7', 'g', '3', '6', '7', '8', 'w', '3', '6', '7', 'd', 'e', 'y', '6', '8', '2', '5', 'y', '6', '8', 'w', 'f', 'd', '6', '8', 'x', '4', '8', '6', 'b', '4', '6', 'g', '6', 'b', '4', 'w', '6', '6', 'b', 'd', 'n', '5', '6', 'b', 'n', 'n', 'm', '6', 'b', 'x', 'w', 'g', '6', 'c', '3', 'n', '6', '6', 'c', '3', 'p', '5', '6', 'c', 'm', '6', 'm', '6', 'c', 'w', 'x', 'e', '6', 'd', 'd', '2', 'y', '6', 'd', 'm', 'x', '7', '6', 'e', '2', 'd', 'g', '6', 'e', '5', '5', '4', '6', 'e', '6', 'p', 'n', '6', 'e', 'c', 'b', 'n', '6', 'e', 'n', 'd', '3', '6', 'f', '2', 'y', 'c', '6', 'f', '8', '5', '7', '6', 'f', 'g', '8', 'c', '6', 'f', 'g', 'd', 'w', '6', 'f', 'n', '8', '4', '6', 'g', '4', '5', 'w', '6', 'g', 'e', '3', 'p', '6', 'g', 'n', 'm', '3', '6', 'm', '5', 'e', 'g', '6', 'm', 'e', 'g', 'e', '6', 'm', 'n', '8', 'n', '6', 'm', 'y', 'g', 'b', '6', 'n', '4', '4', '3', '6', 'n', '5', 'f', 'd', '6', 'n', '6', 'g', 'g', '6', 'n', 'g', '6', 'n', '6', 'n', 'g', '6', 'w', '6', 'p', '2', 'g', 'e', '6', 'p', '7', 'g', 'x', '6', 'p', 'f', 'y', '4', '6', 'p', 'w', 'c', 'n', '6', 'w', 'b', '7', '6', '6', 'w', 'g', '4', 'n', '6', 'w', 'n', 'y', 'c', '6', 'x', 'e', 'n', '4', '6', 'x', 'p', 'm', 'e', '6', 'x', 'x', 'd', 'x', '6', 'y', 'd', 'y', 'p', '7', '2', '8', 'n', '8', '7', '2', 'm', '6', 'f', '7', '3', 'm', 'n', 'x', '7', '4', '8', '5', '3', '7', '4', 'e', 'y', 'g', '7', '5', 'p', 'f', 'w', '7', '6', '3', '4', 'y', '7', '6', '3', '5', '3', '7', '6', 'n', '7', 'p', '7', '6', 'n', 'x', 'n', '7', '6', 'y', '6', 'f', '7', '7', '3', '8', '7', '7', '7', 'n', '6', 'g', '7', '7', 'w', 'p', '4', '7', '8', '5', 'n', '4', '7', '8', 'e', 'e', 'c', '7', 'b', '4', 'b', 'm', '7', 'b', 'b', '7', 'b', '7', 'b', 'w', 'm', '2', '7', 'c', 'd', 'g', 'e', '7', 'c', 'g', 'y', 'm', '7', 'd', '4', '4', 'm', '7', 'd', 'g', 'c', '2', '7', 'd', 'w', 'x', '4', '7', 'd', 'x', 'b', 'd', '7', 'd', 'y', 'w', 'w', '7', 'e', '2', 'y', '7', '7', 'f', '8', 'b', '3', '7', 'f', 'd', 'e', '7', '7', 'f', 'm', 'c', 'y', '7', 'g', '3', 'n', 'f', '7', 'g', 'c', 'e', '6', '7', 'g', 'm', 'f', '3', '7', 'g', 'n', 'g', 'e', '7', 'g', 'p', '4', '7', '7', 'm', '8', 'p', 'x', '7', 'm', 'g', 'm', 'f', '7', 'n', 'n', 'n', 'x', '7', 'p', '8', '5', '2', '7', 'p', 'c', 'd', '7', '7', 'p', 'n', '5', 'g', '7', 'w', '6', '7', 'm', '7', 'w', 'n', '7', '4', '7', 'w', 'n', 'p', 'm', '7', 'w', 'y', 'p', '4', '7', 'x', 'c', 'y', 'd', '7', 'x', 'd', '5', 'm', '7', 'y', '2', 'x', '4', '7', 'y', 'f', '6', '2', '8', '2', '3', 'p', '2', '8', '2', 'f', 'x', '2', '8', '3', '2', 'f', '3', '8', '4', 'w', '7', 'x', '8', '5', '6', '2', '2', '8', '5', 'd', 'x', 'n', '8', '6', '5', 'w', 'm', '8', '6', '8', '4', 'm', '8', '7', 'd', '4', 'c', '8', '7', 'n', 'y', 'm', '8', '8', 'b', 'g', 'x', '8', '8', 'y', '5', '2', '8', 'b', '7', '3', '5', '8', 'b', 'b', 'm', '4', '8', 'b', 'b', 'w', '8', '8', 'c', '2', '3', 'f', '8', 'c', '2', 'w', 'y', '8', 'c', 'c', 'c', 'c', '8', 'c', 'm', '4', '6', '8', 'd', '2', 'n', 'd', '8', 'd', '4', 'w', 'm', '8', 'd', '8', 'e', 'p', '8', 'd', 'b', '6', '7', '8', 'e', '3', '2', 'm', '8', 'e', 'g', 'g', 'g', '8', 'f', 'e', 'x', 'n', '8', 'g', '4', 'y', 'p', '8', 'g', 'e', 'c', 'm', '8', 'g', 'f', '7', 'n', '8', 'g', 'm', 'c', '4', '8', 'g', 'm', 'n', 'x', '8', 'n', '2', 'p', 'g', '8', 'n', '3', '4', 'n', '8', 'n', '4', 'n', '8', '8', 'n', '5', '6', 'm', '8', 'n', '5', 'p', '3', '8', 'n', '5', 'p', 'n', '8', 'n', '6', '2', 'n', '8', 'n', '6', '5', 'n', '8', 'n', 'b', 'e', 'w', '8', 'n', 'e', '4', 'g', '8', 'n', 'n', '7', '3', '8', 'n', 'p', '2', '2', '8', 'n', 'p', 'd', '5', '8', 'n', 'p', 'e', '3', '8', 'p', 'f', 'x', 'x', '8', 'w', '7', '5', '4', '8', 'w', '8', '7', '5', '8', 'w', 'y', '7', 'd', '8', 'x', 'e', 'f', '7', '8', 'y', '6', '3', 'f', '8', 'y', '6', 'b', '3', '8', 'y', 'p', 'd', 'n', 'b', '2', '6', 'n', 'd', 'b', '2', '8', 'g', '8', 'b', '2', 'g', '8', 'e', 'b', '2', 'n', 'e', 'n', 'b', '3', '5', 'f', '6', 'b', '3', 'x', 'p', 'n', 'b', '4', '3', 'n', 'w', 'b', '4', 'd', '7', 'c', 'b', '4', 'n', 'c', 'n', 'b', '4', 'y', '5', 'x', 'b', '5', '5', 'd', '6', 'b', '5', 'd', 'n', '4', 'b', '5', 'f', 'm', '7', 'b', '5', 'n', 'm', 'm', 'b', '5', 'p', 'n', 'n', 'b', '6', '8', '5', 'n', 'b', '6', 'f', '2', 'p', 'b', '8', '4', 'x', 'c', 'b', 'b', 'y', 'm', 'y', 'b', 'c', '8', 'n', 'f', 'b', 'c', 'w', 'n', 'n', 'b', 'd', '3', 'b', '7', 'b', 'd', 'b', 'b', '3', 'b', 'd', 'g', '8', '4', 'b', 'e', '3', 'b', 'p', 'b', 'e', '6', 'n', 'p', 'b', 'e', 'f', 'b', 'd', 'b', 'f', '5', '2', 'c', 'b', 'g', 'b', '4', '8', 'b', 'g', 'd', '4', 'm', 'b', 'g', 'e', 'm', '5', 'b', 'm', '3', 'p', '8', 'b', 'm', 'x', 'p', 'e', 'b', 'n', '5', 'm', 'w', 'b', 'n', 'c', '2', 'f', 'b', 'n', 'c', '5', 'f', 'b', 'n', 'y', '2', '3', 'b', 'n', 'y', '4', 'w', 'b', 'p', '2', 'd', '4', 'b', 'p', '6', 'm', 'w', 'b', 'p', 'w', 'd', '7', 'b', 'w', '4', '4', 'w', 'b', 'w', '5', 'n', 'f', 'b', 'w', '5', 'y', 'm', 'b', 'w', '6', 'n', '6', 'b', 'w', 'm', 'e', 'e', 'b', 'x', 'x', 'f', 'c', 'b', 'y', '5', 'y', '3', 'b', 'y', 'c', '8', '2', 'b', 'y', 'f', 'g', 'n', 'c', '2', 'f', 'b', '7', 'c', '2', 'g', '4', 'd', 'c', '2', 'p', 'g', '6', 'c', '2', 'y', 'n', '8', 'c', '3', '5', '3', 'e', 'c', '3', '5', '7', '2', 'c', '3', 'n', '8', 'x', 'c', '4', '3', 'b', '4', 'c', '4', '5', '2', '7', 'c', '4', '8', '2', 'b', 'c', '4', 'b', 'g', 'd', 'c', '4', 'b', 'n', 'y', 'c', '4', 'm', 'c', 'm', 'c', '5', '5', 'c', '6', 'c', '5', 'x', 'n', 'e', 'c', '6', '7', '4', '5', 'c', '6', 'f', '8', 'g', 'c', '6', 'w', 'e', '6', 'c', '7', '5', '3', 'e', 'c', '7', 'g', 'b', '3', 'c', '7', 'n', 'n', '8', 'c', '8', '6', 'm', 'd', 'c', '8', 'f', 'x', 'y', 'c', '8', 'n', '8', 'c', 'c', 'b', '8', 'c', 'f', 'c', 'c', '8', '4', '5', 'c', 'c', 'f', '2', 'w', 'c', 'c', 'n', '2', 'x', 'c', 'd', '4', 'e', 'g', 'c', 'd', '6', 'p', '4', 'c', 'd', 'c', 'b', '3', 'c', 'd', 'f', '7', '7', 'c', 'd', 'f', 'e', 'n', 'c', 'd', 'm', 'n', '8', 'c', 'e', 'n', '5', '5', 'c', 'e', 'w', 'n', 'm', 'c', 'f', 'c', '2', 'y', 'c', 'f', 'c', '5', '6', 'c', 'f', 'f', 'p', '4', 'c', 'f', 'n', '5', '3', 'c', 'f', 'p', '8', '6', 'c', 'f', 'w', '6', 'e', 'c', 'g', '5', 'd', 'd', 'c', 'g', 'c', 'g', 'b', 'c', 'm', '6', 'y', 'b', 'c', 'n', 'e', 'x', '4', 'c', 'n', 'm', 'n', 'n', 'c', 'n', 'w', 'y', 'c', 'c', 'p', 'c', '8', 'c', 'c', 'p', 'e', '6', '3', 'c', 'w', 'd', 'n', 'x', 'c', 'w', 'g', 'y', 'x', 'c', 'w', 'm', 'n', 'y', 'c', 'x', '3', 'w', 'g', 'c', 'y', '3', 'n', 'w', 'd', '2', '2', 'b', 'd', 'd', '2', '2', 'n', '7', 'd', '2', '2', 'y', '5', 'd', '2', '3', '6', 'n', 'd', '2', 'n', 'b', 'n', 'd', '2', 'y', 'c', 'w', 'd', '3', '7', '8', 'n', 'd', '3', 'c', '7', 'y', 'd', '3', 'c', '8', 'y', 'd', '3', 'y', 'c', 'n', 'd', '4', 'n', '8', '2', 'd', '4', 'p', 'p', 'y', 'd', '6', '6', '6', 'm', 'd', '6', '6', 'c', 'n', 'd', '6', 'f', 'c', 'n', 'd', '7', '5', 'b', '5', 'd', '7', 'c', '5', 'x', 'd', '7', 'e', 'n', '3', 'd', '7', 'n', 'n', '3', 'd', '8', 'd', 'c', 'e', 'd', '8', 'x', 'c', 'n', 'd', 'b', 'e', 'x', '3', 'd', 'b', 'f', 'e', 'n', 'd', 'b', 'n', 'y', '3', 'd', 'b', 'p', 'c', 'd', 'd', 'c', '4', '3', '6', 'd', 'c', 'e', '8', 'y', 'd', 'c', 'n', 'p', '8', 'd', 'd', '5', 'w', '5', 'd', 'd', '7', '6', '4', 'd', 'd', 'c', 'd', 'd', 'd', 'd', 'c', 'n', 'e', 'd', 'd', 'm', 'y', 'g', 'd', 'd', 'n', 'p', 'f', 'd', 'd', 'p', 'y', 'b', 'd', 'e', '4', '5', 'x', 'd', 'e', '7', 'f', '8', 'd', 'e', 'e', 'p', '5', 'd', 'e', 'f', 'y', 'x', 'd', 'e', 'n', 'e', 'b', 'd', 'f', 'n', 'x', '4', 'd', 'm', 'w', '8', 'n', 'd', 'm', 'x', '8', 'p', 'd', 'm', 'x', 'p', '8', 'd', 'n', '2', '6', 'n', 'd', 'n', '2', 'y', 'm', 'd', 'n', '5', 'd', 'f', 'd', 'n', 'm', 'd', '8', 'd', 'n', 'n', 'e', '7', 'd', 'n', 'x', 'd', 'p', 'd', 'p', 'b', 'y', 'd', 'd', 'w', '3', 'n', 'n', 'd', 'w', '6', 'm', 'n', 'd', 'w', '8', 'd', '3', 'd', 'x', 'w', 'c', 'w', 'd', 'y', '3', 'c', 'x', 'd', 'y', 'p', '7', 'n', 'd', 'y', 'x', 'n', 'c', 'e', '2', '5', 'x', 'g', 'e', '2', 'd', '6', '6', 'e', '2', 'm', 'g', '2', 'e', '3', 'n', 'd', 'n', 'e', '4', '3', 'y', 'm', 'e', '4', '6', 'p', 'd', 'e', '4', '6', 'y', 'w', 'e', '4', 'g', 'd', '7', 'e', '5', 'n', '6', '6', 'e', '6', '6', '7', 'x', 'e', '6', 'b', '7', 'y', 'e', '6', 'm', '6', 'p', 'e', '7', '2', 'c', 'd', 'e', '7', '6', 'n', '4', 'e', '7', 'n', 'x', '4', 'e', '7', 'x', '4', '5', 'e', '8', '4', 'n', '2', 'e', '8', 'd', 'x', 'n', 'e', '8', 'e', '5', 'e', 'e', 'b', 'c', 'b', 'x', 'e', 'c', '6', 'p', 'm', 'e', 'c', 'd', '4', 'w', 'e', 'd', 'g', '3', 'p', 'e', 'd', 'w', 'n', 'y', 'e', 'e', '8', 'f', 'g', 'e', 'e', 'n', '2', '3', 'e', 'f', '4', 'm', 'n', 'e', 'f', '4', 'n', 'p', 'e', 'f', 'b', '3', 'f', 'e', 'f', 'e', '6', '2', 'e', 'f', 'g', '7', '2', 'e', 'f', 'g', 'x', '5', 'e', 'f', 'x', '3', '4', 'e', 'g', 'x', 'm', 'p', 'e', 'm', 'w', 'p', 'n', 'e', 'n', '3', '2', 'e', 'e', 'n', '4', 'n', '4', 'e', 'n', 'g', '5', '3', 'e', 'n', 'n', '7', 'n', 'e', 'n', 'n', 'm', 'm', 'e', 'n', 'p', 'w', '2', 'e', 'p', '8', '5', 'x', 'e', 'p', 'p', 'g', '3', 'e', 'w', 'c', 'f', '5', 'e', 'w', 'n', 'x', '8', 'e', 'x', 'c', 'm', 'n', 'e', 'x', 'y', 'c', 'n', 'f', '2', '2', '8', 'n', 'f', '2', '2', 'b', 'n', 'f', '2', 'f', 'g', 'e', 'f', '2', 'm', '8', 'n', 'f', '3', '5', 'x', 'p', 'f', '3', '6', '4', 'x', 'f', '4', 'f', 'n', '2', 'f', '4', 'w', 'f', 'n', 'f', '5', 'c', 'm', '2', 'f', '5', 'e', '5', 'e', 'f', '6', 'n', 'e', '5', 'f', '6', 'w', 'w', '8', 'f', '7', '4', 'x', '3', 'f', '7', '5', '3', 'f', 'f', '7', '5', 'c', 'x', 'f', '7', 'c', 'e', 'y', 'f', '8', '3', 'p', 'n', 'f', '8', '5', '8', 'x', 'f', '8', '5', 'y', '3', 'f', '8', 'f', '8', 'g', 'f', 'b', 'p', '2', 'c', 'f', 'c', '2', 'f', 'f', 'f', 'c', '6', 'x', 'b', 'f', 'c', 'e', 'y', '3', 'f', 'c', 'm', 'e', 'm', 'f', 'c', 'n', 'e', '6', 'f', 'd', 'p', 'g', 'd', 'f', 'e', 'y', 'c', '8', 'f', 'f', 'd', '6', 'p', 'f', 'f', 'n', 'x', 'n', 'f', 'f', 'p', 'x', 'f', 'f', 'g', '3', '8', 'b', 'f', 'g', '7', 'm', 'g', 'f', 'g', '8', 'n', '4', 'f', 'n', 'b', 'f', 'w', 'f', 'n', 'c', 'n', 'b', 'f', 'p', '3', '8', '2', 'f', 'p', '3', 'w', 'y', 'f', 'p', '5', 'w', 'n', 'f', 'p', '7', '6', '2', 'f', 'p', 'w', '7', '6', 'f', 'w', '3', 'b', '2', 'f', 'w', 'x', 'd', 'p', 'f', 'x', 'p', 'w', '3', 'f', 'y', '2', 'n', 'd', 'f', 'y', 'f', 'b', 'n', 'f', 'y', 'w', 'b', '8', 'g', '2', '4', '7', 'w', 'g', '2', '5', '7', '7', 'g', '2', 'f', 'n', 'w', 'g', '3', 'd', 'y', '6', 'g', '3', 'e', 'x', '3', 'g', '5', '5', 'b', '4', 'g', '6', 'n', '7', 'x', 'g', '7', '8', 'g', 'n', 'g', '7', 'f', 'm', 'c', 'g', '7', 'g', 'n', 'f', 'g', '7', 'w', 'x', 'w', 'g', '8', '4', '2', 'c', 'g', '8', '8', '8', 'x', 'g', '8', 'g', 'n', 'd', 'g', 'b', 'x', 'y', 'y', 'g', 'c', '2', '7', '7', 'g', 'c', '2', 'w', 'd', 'g', 'c', '8', '3', 'b', 'g', 'c', 'f', 'g', 'p', 'g', 'c', 'x', '6', 'f', 'g', 'd', '4', 'm', 'f', 'g', 'd', '8', 'f', 'b', 'g', 'd', 'n', 'g', '3', 'g', 'e', 'c', 'm', 'f', 'g', 'e', 'g', 'w', '4', 'g', 'e', 'w', 'f', 'y', 'g', 'f', '2', 'g', '4', 'g', 'f', 'b', 'x', '6', 'g', 'f', 'p', '5', '4', 'g', 'f', 'x', 'c', 'c', 'g', 'g', 'd', '7', 'm', 'g', 'm', '2', 'c', '2', 'g', 'm', '6', 'n', 'n', 'g', 'm', '7', 'n', '8', 'g', 'n', '2', 'd', '3', 'g', 'n', '2', 'x', 'y', 'g', 'n', 'b', 'd', 'e', 'g', 'n', 'b', 'n', '4', 'g', 'n', 'c', '3', 'n', 'g', 'n', 'f', '8', '5', 'g', 'n', 'g', '6', 'e', 'g', 'n', 'y', '6', 'b', 'g', 'p', '2', '2', 'x', 'g', 'p', '7', 'c', '5', 'g', 'p', 'n', 'x', 'n', 'g', 'p', 'x', 'n', 'g', 'g', 'w', '4', '6', '8', 'g', 'w', '5', '3', 'm', 'g', 'w', 'n', '5', '3', 'g', 'w', 'n', 'm', '6', 'g', 'x', 'x', '2', 'p', 'g', 'x', 'x', 'p', 'f', 'g', 'y', '4', '3', '3', 'g', 'y', '5', 'b', 'f', 'g', 'y', '8', 'x', 'b', 'g', 'y', 'm', 'm', 'n', 'm', '2', '2', 'e', '3', 'm', '2', '3', 'b', 'p', 'm', '2', '5', '7', '6', 'm', '2', 'n', 'f', '4', 'm', '3', '5', '8', '8', 'm', '3', 'b', '5', 'p', 'm', '3', 'w', 'f', 'w', 'm', '4', '4', '8', 'b', 'm', '4', '5', '7', 'd', 'm', '4', 'f', 'd', '8', 'm', '4', 'g', '8', 'g', 'm', '5', 'm', 'e', 'g', 'm', '5', 'y', 'm', '2', 'm', '6', '7', 'b', '3', 'm', '6', 'n', '4', 'x', 'm', '7', '4', 'd', 'm', 'm', '7', '5', 'b', 'f', 'm', '8', 'g', 'm', 'x', 'm', '8', 'm', '4', 'x', 'm', 'b', '4', 'e', 'n', 'm', 'b', 'f', '5', '8', 'm', 'b', 'p', '2', 'y', 'm', 'c', '3', '5', 'n', 'm', 'c', '8', 'w', '2', 'm', 'c', 'c', '2', 'x', 'm', 'c', 'g', '4', '3', 'm', 'c', 'y', 'f', 'x', 'm', 'd', '3', '4', '4', 'm', 'd', 'd', 'g', 'b', 'm', 'd', 'x', 'p', 'n', 'm', 'd', 'y', 'p', '7', 'm', 'e', 'n', '4', 'f', 'm', 'f', 'b', '3', 'x', 'm', 'f', 'c', '3', '5', 'm', 'g', '5', 'n', 'n', 'm', 'g', 'd', 'w', 'b', 'm', 'g', 'g', 'c', 'e', 'm', 'g', 'w', '3', 'n', 'm', 'm', '3', 'n', 'n', 'm', 'm', 'c', '5', 'n', 'm', 'm', 'f', 'm', '6', 'm', 'm', 'g', '2', 'm', 'm', 'm', 'g', '3', '8', 'm', 'm', 'y', '5', 'n', 'm', 'n', '5', 'c', '4', 'm', 'n', 'e', 'f', '5', 'm', 'p', '7', 'w', 'p', 'm', 'p', 'm', 'y', '5', 'm', 'p', 'x', 'f', 'b', 'm', 'w', '5', 'p', '2', 'm', 'w', 'd', 'f', '6', 'm', 'w', 'x', 'w', 'p', 'm', 'x', '8', 'b', 'b', 'm', 'x', 'n', 'w', '4', 'm', 'x', 'y', 'x', 'w', 'm', 'y', '8', '4', 'e', 'm', 'y', 'c', '3', 'c', 'm', 'y', 'e', '6', '8', 'm', 'y', 'f', '8', '2', 'n', '2', '6', '5', 'y', 'n', '2', 'b', 'y', '7', 'n', '2', 'g', 'm', 'g', 'n', '3', '3', '6', 'e', 'n', '3', '7', '3', 'n', 'n', '3', 'b', 'm', '6', 'n', '3', 'f', 'f', 'n', 'n', '3', 'm', '6', 'x', 'n', '3', 'x', '4', 'c', 'n', '4', '6', '4', 'c', 'n', '4', 'b', '4', 'm', 'n', '4', 'c', 'p', 'y', 'n', '4', 'w', 'w', 'n', 'n', '4', 'x', 'x', '5', 'n', '5', 'c', 'm', '7', 'n', '5', 'n', '8', 'b', 'n', '5', 'w', '5', 'g', 'n', '5', 'w', 'b', 'g', 'n', '5', 'x', '2', 'n', 'n', '6', 'f', '4', 'b', 'n', '6', 'n', 'n', '2', 'n', '6', 'x', 'c', '5', 'n', '7', 'd', 'y', 'b', 'n', '7', 'e', 'b', 'x', 'n', '7', 'e', 'n', 'n', 'n', '7', 'f', 'f', '2', 'n', '7', 'g', '4', 'f', 'n', '7', 'm', 'e', 'b', 'n', '8', 'f', 'p', '6', 'n', '8', 'p', 'f', 'e', 'n', '8', 'y', 'd', 'd', 'n', 'b', '2', '6', '7', 'n', 'b', '4', '5', 'd', 'n', 'b', 'c', 'g', 'b', 'n', 'b', 'f', '8', 'm', 'n', 'b', 'f', 'x', '5', 'n', 'b', 'm', 'x', '7', 'n', 'b', 'p', '3', 'e', 'n', 'b', 'w', 'n', 'n', 'n', 'b', 'w', 'p', 'n', 'n', 'c', '4', 'y', 'g', 'n', 'c', 'f', 'g', 'b', 'n', 'c', 'w', '4', 'g', 'n', 'c', 'w', 'w', '7', 'n', 'c', 'y', 'x', '8', 'n', 'd', '5', 'w', 'g', 'n', 'd', 'e', 'c', 'c', 'n', 'd', 'g', '2', 'b', 'n', 'd', 'm', 'e', '7', 'n', 'd', 'y', 'f', 'e', 'n', 'e', '3', '2', '5', 'n', 'e', 'e', 'c', 'd', 'n', 'e', 'g', 'g', 'n', 'n', 'f', '2', 'n', '8', 'n', 'f', '7', 'b', 'n', 'n', 'f', '8', 'b', '8', 'n', 'f', 'b', 'g', '8', 'n', 'f', 'c', 'b', '5', 'n', 'f', 'c', 'w', 'y', 'n', 'f', 'd', '8', 'g', 'n', 'f', 'g', '2', '3', 'n', 'f', 'n', 'd', 'w', 'n', 'g', '2', 'g', 'w', 'n', 'g', '4', '6', 'm', 'n', 'g', '6', 'y', 'p', 'n', 'g', '7', '5', '6', 'n', 'g', 'n', '2', '6', 'n', 'm', '2', '4', '8', 'n', 'm', '4', '6', 'n', 'n', 'm', 'w', '4', '6', 'n', 'm', 'y', '2', 'x', 'n', 'n', '4', 'w', 'x', 'n', 'n', '6', 'm', 'g', 'n', 'n', 'f', '8', 'b', 'n', 'n', 'f', 'x', '3', 'n', 'n', 'g', 'x', 'c', 'n', 'n', 'n', '5', '7', 'n', 'n', 'n', '5', 'p', 'n', 'n', 'p', '4', 'e', 'n', 'n', 'y', '5', 'e', 'n', 'p', 'x', 'b', '7', 'n', 'w', '5', 'b', '2', 'n', 'w', 'f', 'd', 'e', 'n', 'w', 'g', '2', 'm', 'n', 'w', 'n', 'c', 'n', 'n', 'x', 'c', '8', '3', 'n', 'x', 'c', 'm', 'n', 'n', 'x', 'n', '4', 'f', 'n', 'x', 'x', '2', '5', 'n', 'x', 'x', 'f', '8', 'n', 'y', '3', 'd', 'w', 'n', 'y', '3', 'n', 'n', 'n', 'y', '5', 'd', 'p', 'n', 'y', '8', 'n', 'p', 'n', 'y', 'b', 'c', 'x', 'p', '2', '4', 'g', 'n', 'p', '2', 'd', 'w', '7', 'p', '2', 'm', '6', 'n', 'p', '2', 'x', '7', 'x', 'p', '2', 'y', 'm', '2', 'p', '4', 'n', 'm', '4', 'p', '4', 'p', 'd', 'e', 'p', '5', '7', 'f', 'n', 'p', '5', 'g', '5', 'm', 'p', '5', 'n', 'c', 'e', 'p', '6', 'm', 'n', '8', 'p', '7', 'f', 'y', 'p', 'p', '8', 'c', '2', '4', 'p', '8', 'n', 'g', 'x', 'p', '8', 'w', 'w', 'f', 'p', 'b', 'p', 'g', 'c', 'p', 'c', 'e', 'd', 'e', 'p', 'c', 'm', '7', 'f', 'p', 'c', 'p', 'g', '6', 'p', 'd', 'c', 'p', '4', 'p', 'd', 'w', '3', '8', 'p', 'd', 'y', 'c', '8', 'p', 'e', '4', 'x', 'n', 'p', 'f', '4', 'n', 'b', 'p', 'f', '5', 'n', 'g', 'p', 'g', '2', 'p', 'm', 'p', 'g', '2', 'y', 'x', 'p', 'g', '4', 'b', 'f', 'p', 'g', 'g', '3', 'n', 'p', 'g', 'm', '2', 'e', 'p', 'g', 'm', 'n', '2', 'p', 'g', 'w', 'n', 'p', 'p', 'm', '3', '6', '3', 'p', 'm', '4', '7', 'f', 'p', 'm', 'd', '3', 'w', 'p', 'm', 'e', '8', '6', 'p', 'm', 'f', '5', 'w', 'p', 'm', 'g', '5', '5', 'p', 'n', '7', 'p', 'n', 'p', 'n', 'm', 'x', 'f', 'p', 'n', 'n', 'w', 'y', 'p', 'p', '5', '4', '6', 'p', 'p', '8', '7', 'n', 'p', 'p', 'w', 'y', 'd', 'p', 'p', 'x', '7', '7', 'p', 'w', '5', 'n', 'c', 'p', 'w', 'e', 'b', 'm', 'p', 'w', 'm', 'b', 'n', 'p', 'w', 'n', '5', 'e', 'p', 'x', '2', 'x', 'p', 'p', 'x', '8', 'n', '8', 'p', 'x', 'd', 'w', 'p', 'p', 'x', 'n', 'e', '8', 'p', 'y', 'b', 'e', 'e', 'p', 'y', 'e', 'f', 'b', 'p', 'y', 'f', '6', '5', 'p', 'y', 'm', '7', 'p', 'w', '2', 'e', '8', '7', 'w', '2', 'n', '7', 'e', 'w', '2', 'y', 'p', '7', 'w', '4', '6', 'e', 'p', 'w', '4', '8', 'c', 'w', 'w', '4', 'c', 'd', 'c', 'w', '4', 'c', 'n', 'n', 'w', '4', 'n', 'f', 'x', 'w', '4', 'x', '2', 'm', 'w', '5', '2', 'f', 'n', 'w', '6', 'p', 'x', 'y', 'w', '6', 'y', 'n', 'e', 'w', '7', '5', 'w', '8', 'w', '7', 'e', '6', 'm', 'w', '8', 'b', 'n', 'x', 'w', '8', 'f', '3', '6', 'w', 'b', '3', 'e', 'd', 'w', 'b', 'n', 'c', 'w', 'w', 'c', '2', 'b', 'd', 'w', 'c', 'e', '5', 'n', 'w', 'd', '2', 'g', 'b', 'w', 'd', 'd', 'c', 'p', 'w', 'd', 'w', 'w', '8', 'w', 'e', 'c', 'f', 'd', 'w', 'f', '6', '8', '4', 'w', 'f', 'y', '5', 'm', 'w', 'g', '6', '2', '5', 'w', 'g', 'n', 'w', 'p', 'w', 'm', '4', '7', 'f', 'w', 'm', '7', '4', '6', 'w', 'm', 'p', 'm', 'p', 'w', 'n', 'm', 'y', 'n', 'w', 'n', 'p', 'e', 'c', 'w', 'w', 'm', 'n', '6', 'w', 'x', 'c', 'n', '8', 'w', 'x', 'y', '4', 'n', 'w', 'y', 'c', '2', '5', 'w', 'y', 'e', '8', '5', 'x', '2', '7', '7', 'e', 'x', '2', 'c', 'n', 'n', 'x', '3', '4', '7', 'n', 'x', '3', '6', '2', 'g', 'x', '3', '7', 'b', 'f', 'x', '3', '8', 'f', 'n', 'x', '3', 'd', 'e', 'b', 'x', '3', 'f', 'w', 'f', 'x', '4', '4', 'n', '4', 'x', '4', '5', '8', 'w', 'x', '4', 'f', '7', 'g', 'x', '4', 'g', 'g', '5', 'x', '4', 'p', 'n', 'p', 'x', '5', 'f', '5', '4', 'x', '5', 'n', 'y', 'n', 'x', '6', 'b', '5', 'm', 'x', '6', 'p', 'd', 'b', 'x', '7', '4', '2', '2', 'x', '7', '4', 'b', '2', 'x', '7', '5', '4', '7', 'x', '7', '6', 'm', 'n', 'x', '7', '7', '4', '6', 'x', '7', '7', '5', 'w', 'x', '8', 'e', '8', 'n', 'x', '8', 'x', 'n', 'p', 'x', 'b', 'c', 'b', 'x', 'x', 'b', 'e', 'm', '6', 'x', 'c', '6', '8', 'n', 'x', 'c', 'e', '8', 'd', 'x', 'c', 'f', '8', '8', 'x', 'c', 'm', 'b', 'p', 'x', 'd', 'c', 'n', '4', 'x', 'd', 'n', '6', '5', 'x', 'e', '6', 'e', 'b', 'x', 'e', '8', 'x', 'm', 'x', 'e', 'm', 'y', 'g', 'x', 'f', '4', 'p', '4', 'x', 'f', '5', 'g', '7', 'x', 'f', 'g', '6', '5', 'x', 'f', 'g', 'x', 'b', 'x', 'f', 'n', '6', 'n', 'x', 'g', 'c', 'x', 'y', 'x', 'm', 'c', 'y', 'm', 'x', 'n', 'd', '3', 'y', 'x', 'n', 'f', 'x', '5', 'x', 'n', 'g', 'x', 'c', 'x', 'n', 'n', '4', 'd', 'x', 'n', 'n', 'c', '3', 'x', 'p', '2', '4', 'p', 'x', 'w', '4', '6', '5', 'x', 'w', 'x', '7', 'd', 'x', 'x', 'b', 'm', '5', 'x', 'x', 'n', 'e', 'y', 'x', 'x', 'w', '4', '4', 'x', 'y', 'm', 'f', 'n', 'x', 'y', 'n', 'c', 'c', 'x', 'y', 'y', 'y', 'w', 'y', '2', '4', '3', '6', 'y', '2', 'x', 'g', '4', 'y', '2', 'y', 'e', '8', 'y', '3', '2', 'y', 'y', 'y', '3', '3', 'n', 'm', 'y', '3', 'c', '5', '8', 'y', '4', '8', 'c', '3', 'y', '4', 'e', 'c', '2', 'y', '4', 'g', '3', 'b', 'y', '4', 'n', '6', 'm', 'y', '5', '3', 'c', '2', 'y', '5', 'd', 'p', 'p', 'y', '5', 'g', '8', '7', 'y', '5', 'n', '6', 'd', 'y', '5', 'w', '2', '8', 'y', '7', 'd', '7', '5', 'y', '7', 'm', 'n', 'm', 'y', '7', 'x', '8', 'p', 'y', '8', '6', '6', 'y', 'y', 'b', 'f', 'x', '6', 'y', 'c', 'm', 'c', 'w', 'y', 'c', 'n', 'f', 'c', 'y', 'd', '3', '8', 'e', 'y', 'd', '3', 'm', '3', 'y', 'd', '7', '5', '5', 'y', 'd', 'd', '3', 'g', 'y', 'd', 'g', '8', 'n', 'y', 'e', 'm', 'y', '4', 'y', 'e', 'w', '6', 'p', 'y', 'e', 'y', 'n', '4', 'y', 'f', '2', '8', 'd', 'y', 'f', '3', '4', '7', 'y', 'f', '4', '2', '4', 'y', 'f', 'd', 'n', '7', 'y', 'g', '5', 'b', 'b', 'y', 'g', 'e', 'n', 'n', 'y', 'g', 'f', 'w', 'e', 'y', 'm', 'p', '7', 'g', 'y', 'p', 'p', '8', 'f', 'y', 'p', 'w', '3', 'd', 'y', 'w', '6', '6', '7', 'y', 'w', '7', 'n', 'y', 'y', 'w', 'n', '6', 'f', 'y', 'x', '2', 'd', '4', 'y', 'x', 'd', '7', 'm', 'y', 'y', '8', '2', '4', 'y', 'y', 'g', '5', 'g', 'y', 'y', 'n', '5', '7']\n"
     ]
    }
   ],
   "source": [
    "def run_training():\n",
    "    img_files = glob(Data_DIR+\"\\*.png\")\n",
    "    targets = [re.split(r\"\\\\|\\.\", x)[-2] for x in img_files]\n",
    "    targets = [[c for c in x] for x in targets]\n",
    "    targets_flat = [c for clist in targets for c in clist]\n",
    "    print(targets)\n",
    "    print(targets_flat)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1b20169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe74875b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d5d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952e9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bf93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d77111",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 300\n",
    "h = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7334561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dines\\AppData\\Local\\Temp\\ipykernel_9984\\3655700753.py:5: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  img = img.resize((h, w), resample=Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(r\"C:\\Users\\dines\\Music\\Work\\pytorch_practice\\captcha_images_v2\\226md.png\").convert('RGB')\n",
    "img = img.resize((h, w), resample=Image.BILINEAR)\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ffbbbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agu = albumentations.Compose(\n",
    "[\n",
    "    albumentations.Normalize(always_apply=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2099df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 70, 3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agu = agu(image=img)['image']\n",
    "agu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "417f693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300, 70)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(agu, (2, 0, 1)).astype(np.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "34aa6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os, re\n",
    "DATA_DIR = r\"C:\\Users\\dines\\Music\\Work\\pytorch_practice\\captcha_images_v2\"\n",
    "\n",
    "image_files = glob(os.path.join(DATA_DIR, '*.png'))\n",
    "# targets = [re.split(r'\\\\|\\.', s)[-2] for s in sample]\n",
    "# list_targets = [[c for c in t] for t in targets]\n",
    "# flat_targets = [c for lt in list_targets for c in lt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b6a5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_orig = [re.split(r\"\\\\|\\.\", x)[-2] for x in image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "81a1e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [[i for i in c] for c in targets_orig]\n",
    "flat_targets = [c for t in targets for c in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "750e932d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(flat_targets)\n",
    "target_encode = [le.transform(t) for t in targets]\n",
    "target_encode = np.array(target_encode)+1\n",
    "len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e070f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 5)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d9eff844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0749a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ae1ffdff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (4043075983.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dines\\AppData\\Local\\Temp\\ipykernel_9984\\4043075983.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    torch.full(size=(1,), 5)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.full(size=(1,), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b48431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0463, -0.3403,  0.4453, -0.2793, -0.2187, -0.3218,  0.2980, -0.3939,\n",
       "          0.0555, -0.1627]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "x = torch.randn((1, 5))\n",
    "s = SimpleNet()\n",
    "s(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4347cf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0434,  0.5636,  0.0297, -0.0237,  0.2357,  0.1498,  0.1792,  0.0093,\n",
       "         -0.2113,  0.4296]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "s = SimpleNet()\n",
    "s(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7935a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f02517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7420,  0.5745,  0.9845, -0.9023,  0.9784],\n",
      "        [ 0.5309,  1.2966, -0.4561,  0.3749, -0.3176],\n",
      "        [-0.7510, -0.4064, -0.5270, -0.7478,  1.8866],\n",
      "        [ 1.1538, -0.0319,  0.4285, -0.1527, -0.3473],\n",
      "        [-0.1989, -0.0547, -0.6555,  1.5216, -1.3756]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9845, 1.2966, 1.8866, 1.1538, 1.5216]),\n",
       "indices=tensor([2, 1, 4, 0, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((5, 5))\n",
    "print(x)\n",
    "torch.max(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58beb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e194ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 75, 300])\n",
      "torch.Size([1, 128, 37, 150])\n",
      "torch.Size([1, 64, 37, 150])\n",
      "torch.Size([1, 64, 18, 75])\n",
      "torch.Size([1, 75, 64, 18])\n",
      "torch.Size([1, 75, 1152])\n",
      "torch.Size([1, 75, 64])\n",
      "torch.Size([1, 75, 64])\n",
      "torch.Size([1, 75, 64])\n",
      "torch.Size([1, 75, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_char):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.fc1 = nn.Linear(1152, 64)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.lstm = nn.GRU(64, 32, bidirectional=True, dropout=0.25, batch_first=True, num_layers=2)\n",
    "        self.fc2 = nn.Linear(64, num_char+1)\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "        btch, channels, height, width = images.size()\n",
    "        x = self.conv1(images)\n",
    "        print(x.size())\n",
    "        x = self.pool1(x)\n",
    "        print(x.size())\n",
    "        x = self.conv2(x)\n",
    "        print(x.size())\n",
    "        x = self.pool2(x)\n",
    "        print(x.size())\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        print(x.size())\n",
    "        x = x.view(btch, x.size(1), -1)\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(x.size())\n",
    "        x = self.drop(x)\n",
    "        print(x.size())\n",
    "        x, _  = self.lstm(x)\n",
    "        print(x.size())\n",
    "        self.fc2(x)\n",
    "        print(x.size())\n",
    "        return x, None\n",
    "    \n",
    "images = torch.randn(1, 3, 75, 300)\n",
    "targets = torch.randint(1, 20, (1, 19))\n",
    "model = Model(19)\n",
    "x, loss = model(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596ad71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c5ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4077b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bdb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bba15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85f98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
